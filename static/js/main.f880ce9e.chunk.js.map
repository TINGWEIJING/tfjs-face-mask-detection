{"version":3,"sources":["styles.js","utils.js","App.js","reportWebVitals.js","index.js"],"names":["styles","root","height","width","display","alignItems","backgroundColor","flexDirection","webCamParentPanel","justifyContent","margin","padding","gap","webCamPanel","settingPanel","faceMaskPanel","faceMaskContainer","webCamStackItem","position","top","left","marginLeft","getWindowDimensions","window","visualViewport","buildDetectedObjects","scores","threshold","boxes","drawHeight","drawWidth","captureHeight","captureWidth","detectionObjects","i","len","length","bbox","minY","minX","maxY","maxX","oriMinY","parseInt","oriMinX","slideBox","push","label","score","cropBox","boxInd","getWebCamInfos","a","navigator","mediaDevices","enumerateDevices","console","log","deviceName","deviceId","then","devices","webCamInfos","kind","catch","err","name","message","webCamRatios","test_img_url","process","App","webcamRef","useRef","multiFaceCanvasRef","Array","fill","useState","faceDetectionScores","setFaceDetectionScores","maskClassificationScores","setMaskClassificationScores","detectionModel","setDetectionModel","classificationModel","setClassificationModel","testImgDim","setTestImgDim","isUsingWebcam","setIsUsingWebcam","selectedWebCamInfo","setSelectedWebCamInfo","availableWebCamInfos","setAvailableWebCamInfos","windowDimensions","setWindowDimensions","useEffect","handleResize","addEventListener","removeEventListener","utils","windowHeight","windowWidth","verticalPanelSplitPercentage","horizontalPanelSplitPercentage","webCamPanelHeight","webCamPanelWidth","targetWebCamHeight","targetWebCamWidth","expectedWebCamHeight","expectedWebCamWidth","oriImgWidth","oriImgHeight","oriImgRatio","targetImgHeight","expectedImgHeight","expectedImgWidth","undefined","faceRenderCanvasHeight","loadModels","dispose","tf","onProgress","fractions","loadedDetectionModel","loadedClassificationModel","onInferencing","current","video","readyState","inputData","cnvs","document","getElementById","ctx","getContext","font","textBaseline","rawImgTensor","fromPixels","inputTensor","transpose","expandDims","executeAsync","res","limitLen","detection_boxes","arraySync","detection_scores","dataSync","detections","_faceDetectionScores","_maskClassificationScores","clearRect","x","y","strokeStyle","lineWidth","strokeRect","map","value","index","resizeImgsTensor","stackImgTensor","tile","reshape","shape","cropAndResize","_allMaskClassificationScores","execute","returnedImgs","faceCanvas","toPixels","finally","_","captureInterval","setInterval","clearInterval","img","Image","src","onload","naturalHeight","naturalWidth","className","style","flexBasis","audio","id","ref","screenshotQuality","screenshotFormat","videoConstraints","facingMode","zIndex","alt","FormGroup","FormControl","sx","m","minWidth","size","InputLabel","Select","labelId","onChange","event","target","autoWidth","MenuItem","FormControlLabel","control","Switch","checked","inputProps","labelPlacement","item","labelName","faceScoreLabel","maskScoreLabel","toFixed","el","reportWebVitals","onPerfEntry","Function","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode"],"mappings":"qgBAAaA,G,OAAS,CACpBC,KAAM,CACJC,OAAQ,QACRC,MAAO,QACPC,QAAS,OACTC,WAAY,UACZC,gBAAiB,UACjBC,cAAe,UAEjBC,kBAAmB,CACjBL,MAAO,OACPG,gBAAiB,UACjBF,QAAS,OACTK,eAAgB,SAChBJ,WAAY,SACZE,cAAe,MACfG,OAAQ,EACRC,QAAS,EACTC,IAAK,GAEPC,YAAa,CACXT,QAAS,OACTF,OAAQ,OACRI,gBAAiB,UACjBG,eAAgB,SAChBJ,WAAY,SACZK,OAAQ,EACRC,QAAS,EACTC,IAAK,GAEPE,aAAc,CACZV,QAAS,OACTF,OAAQ,OACRI,gBAAiB,UACjBG,eAAgB,SAChBJ,WAAY,SACZK,OAAQ,EACRC,QAAS,EACTC,IAAK,GAEPG,cAAe,CACbX,QAAS,OACTE,gBAAiB,UACjBG,eAAgB,eAChBJ,WAAY,SACZK,OAAQ,EACRC,QAAS,EACTC,IAAK,GAEPI,kBAAmB,CACjBZ,QAAS,OACTK,eAAgB,SAChBJ,WAAY,SACZK,OAAQ,EACRC,QAAS,EACTC,IAAK,EACLL,cAAe,UAEjBU,gBAAiB,CACfC,SAAU,WACVC,IAAK,EACLC,KAAM,EACNC,WAAY,UC5DhB,SAASC,IAEP,MAA0BC,OAAOC,eACjC,MAAO,CACLrB,MAFF,EAAQA,MAGND,OAHF,EAAeA,QAOV,IAiDMuB,EAAuB,SAClCC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,GAMA,IAJA,IAAMC,EAAmB,GAErBC,EAAI,EACFC,EAAMT,EAAOU,OACZF,EAAIC,KACLT,EAAOQ,GAAKP,IADF,CAId,IAAMU,EAAO,GACPC,EAAOV,EAAM,GAAGM,GAAG,GAAKL,EACxBU,EAAOX,EAAM,GAAGM,GAAG,GAAKJ,EACxBU,EAAOZ,EAAM,GAAGM,GAAG,GAAKL,EACxBY,EAAOb,EAAM,GAAGM,GAAG,GAAKJ,EAC9BO,EAAK,GAAKE,EACVF,EAAK,GAAKC,EACVD,EAAK,GAAKI,EAAOF,EACjBF,EAAK,GAAKG,EAAOF,EAEjB,IAAMI,EAAUC,SAASf,EAAM,GAAGM,GAAG,GAAKH,GACpCa,EAAUD,SAASf,EAAM,GAAGM,GAAG,GAAKF,GAGpCa,EAAW,CACfH,EACAE,EAJcD,SAASf,EAAM,GAAGM,GAAG,GAAKH,GAK9BW,EAAU,EAJNC,SAASf,EAAM,GAAGM,GAAG,GAAKF,GAK9BY,EAAU,GAEtBX,EAAiBa,KAAK,CACpBC,MAAO,OACPC,MAAOtB,EAAOQ,GACdG,KAAMA,EACNQ,SAAUA,EACVI,QAASrB,EAAM,GAAGM,GAClBgB,OAAQhB,IAEVA,IAEF,OAAOD,GAuBIkB,EAAc,uCAAG,sBAAAC,EAAA,yDACvBC,UAAUC,cAAiBD,UAAUC,aAAaC,iBAD3B,uBAE1BC,QAAQC,IAAI,qCAFc,kBAGnB,CACL,CACEC,WAAY,KACZC,SAAU,QANY,uBAUfN,UAAUC,aACpBC,mBACAK,MAAK,SAAUC,GAId,IAHA,IAAIC,EAAc,GACd5B,EAAI,EACFC,EAAM0B,EAAQzB,OACbF,EAAIC,GACe,eAApB0B,EAAQ3B,GAAG6B,MACbD,EAAYhB,KAAK,CACfY,WAAYG,EAAQ3B,GAAGa,MACvBY,SAAUE,EAAQ3B,GAAGyB,WAGzBzB,IAEF,OAAO4B,KAERE,OAAM,SAAUC,GAEf,OADAT,QAAQC,IAAIQ,EAAIC,KAAO,KAAOD,EAAIE,SAC3B,CACL,CACET,WAAY,KACZC,SAAU,UAhCU,mFAAH,qD,YCpHrBS,EAAe,CAAC,GAAK,EAAG,EAAI,GAQ5BC,EAAY,UAAMC,4BAAN,0BAkhBHC,MAhhBf,WACE,IAAMC,EAAYC,iBAAO,MACnBC,EAAqBD,iBAAOE,MATR,GASmCC,KAAK,IAClE,EAAsDC,mBAAS,IAA/D,mBAAOC,EAAP,KAA4BC,EAA5B,KACA,EAAgEF,mBAAS,IAAzE,mBAAOG,EAAP,KAAiCC,EAAjC,KACA,EAA4CJ,mBAAS,MAArD,mBAAOK,EAAP,KAAuBC,EAAvB,KACA,EAAsDN,mBAAS,MAA/D,mBAAOO,EAAP,KAA4BC,EAA5B,KACA,EAAoCR,mBAAS,IAA7C,mBAAOS,EAAP,KAAmBC,EAAnB,KACA,EAA0CV,oBAAS,GAAnD,mBAAOW,EAAP,KAAsBC,EAAtB,KACA,EAAoDZ,mBAAS,CAC3DnB,WAAY,GACZC,SAAU,KAFZ,mBAAO+B,EAAP,KAA2BC,EAA3B,KAIA,EAAwDd,mBAAS,IAAjE,mBAAOe,EAAP,KAA6BC,GAA7B,KACA,GDqIK,WACL,MAAgDhB,mBAC9CvD,KADF,mBAAOwE,EAAP,KAAyBC,EAAzB,KAaA,OATAC,qBAAU,WACR,SAASC,IACPF,EAAoBzE,KAItB,OADAC,OAAO2E,iBAAiB,SAAUD,GAC3B,kBAAM1E,OAAO4E,oBAAoB,SAAUF,MACjD,IAEIH,EClJLM,GADcC,GAAhB,GAAQnG,OAA6BoG,GAArC,GAA8BnG,MAG9B,GD9BmC,SACnCkG,EACAC,EACAC,EACAC,EACApC,GAEA,IAAMqC,EAAqBJ,EAAeE,EAAgC,IACpEG,EAAoBJ,EAAcE,EAAkC,IACpEG,EAAqBD,EAAmBtC,EAAa,GACrDwC,EAAoBH,EAAoBrC,EAAa,GACvDyC,EAAuBJ,EACvBK,EAAsBJ,EAO1B,OANIC,EAAqBF,EACvBK,EAAsBF,EAEtBC,EAAuBF,EAGlB,CACLD,iBAAkBA,EAClBD,kBAAmBA,EACnBK,oBAAqBA,EACrBD,qBAAsBA,GCYpBT,CACFC,GACAC,GAjCiC,GACE,GAmCnClC,GATAsC,GADF,GACEA,iBACAD,GAFF,GAEEA,kBACAK,GAHF,GAGEA,oBACAD,GAJF,GAIEA,qBAYF,GDnBgC,SAChCE,EACAC,EACAN,EACAD,GAEA,IAAMQ,EAAcF,EAAcC,EAC5BE,EAAkBR,EAAmBO,EAEvCE,EAAoBV,EACpBW,EAAmBV,EAMvB,OALIQ,EAAkBT,EACpBW,EAJqBX,EAAoBQ,EAMzCE,EAAoBD,EAEf,CACLE,iBAAkBA,EAClBD,kBAAmBA,GCC2Bf,MAHnBiB,IAA3B/B,EAAWyB,YAA4BzB,EAAWyB,YAAc,OAEpCM,IAA5B/B,EAAW0B,aAA6B1B,EAAW0B,aAAe,EAIlEN,GACAD,IAJMW,GAAR,GAAQA,iBAAkBD,GAA1B,GAA0BA,kBAMpBG,GACU,GAAZjB,GAAuD,IAAO,GAY5DkB,GAAU,uCAAG,8BAAAnE,EAAA,6DAEM,OAAnB8B,GACFA,EAAesC,UAEW,OAAxBpC,GACFA,EAAoBoC,UANL,SAQkBC,IAjEN,iCAmE3B,CACEC,WAAY,SAACC,OAXA,cAQXC,EARW,gBAgBuBH,IAvE1C,2CAyEI,CACEC,WAAY,SAACC,OAnBA,cAgBXE,EAhBW,OAwBjB1C,EAAkByC,GAClBvC,EAAuBwC,GACvBrE,QAAQC,IAAI,iBA1BK,kBA2BV,CAACmE,EAAsBC,IA3Bb,4CAAH,qDA8BVC,GAAa,uCAAG,WAAO5C,EAAgBE,GAAvB,+BAAAhC,EAAA,yDACE,MAAlB8B,GAAiD,MAAvBE,EADV,oDAaW,qBAAtBZ,EAAUuD,SACK,OAAtBvD,EAAUuD,SAC6B,IAAvCvD,EAAUuD,QAAQC,MAAMC,WAfN,iBAkBlBC,EAAY1D,EAAUuD,QAAQC,MAC9BG,EAAOC,SAASC,eAAe,YAG/B7D,EAAUuD,QAAQC,MAAM7H,MAAQ2G,GAChCtC,EAAUuD,QAAQC,MAAM9H,OAAS2G,GAEjCsB,EAAKhI,MAAQ2G,GACbqB,EAAKjI,OAAS2G,GAGdhF,EAAagF,GACb/E,EAAYgF,GACZ/E,EAAgB,IAChBC,EAAe,KAhCG,2BAiCRwD,EAjCQ,iBAmClB0C,EAAYE,SAASC,eAAe,aACpCF,EAAOC,SAASC,eAAe,gBAG1BlI,MAAQiH,GACbe,EAAKjI,OAASiH,GAGdtF,EAAasF,GACbrF,EAAYsF,GACZrF,EAAgBoF,GAChBnF,EAAeoF,GA9CG,0DAoDdkB,EAAMH,EAAKI,WAAW,MAGf,kBACbD,EAAIE,KADS,kBAEbF,EAAIG,aAAe,MAGbC,EAAejB,IAAWkB,WAAWT,GACrCU,EAAcnB,KAAQ,WAC1B,OAAOiB,EAAaG,UAAU,CAAC,EAAG,EAAG,IAAIC,gBAG3C5D,EACG6D,aAAaH,GACbhF,MAAK,SAACoF,GASL,IAcI9G,EACAC,EACA8G,EAhBEC,EAAkBF,EAAI,GAAGG,YACzBC,EAAmBJ,EAAI,GAAGK,WAE1BC,EAAalD,EACjBgD,EACA,GACAF,EACArH,EACAC,EACAC,EACAC,GAOIuH,EAAuB5E,MAtLT,GAsLoCC,KAAK,MACvD4E,EAA4B7E,MAvLd,GAuLyCC,KAAK,MAElE,GAAI0E,EAAWlH,OAAS,EAAG,CAQzB,IANAF,EAAI,EACJC,EAAMmH,EAAWlH,OACjB6G,EA7LkB,EAgMlBX,EAAImB,UAAU,EAAG,EAAG5C,GAAsBC,IACnC5E,EAAIC,GAAK,CACd,IAAMuH,EAAIJ,EAAWpH,GAAX,KAAsB,GAC1ByH,EAAIL,EAAWpH,GAAX,KAAsB,GAC1B/B,EAAQmJ,EAAWpH,GAAX,KAAsB,GAC9BhC,EAASoJ,EAAWpH,GAAX,KAAsB,GAGrCoG,EAAIsB,YAAc,UAClBtB,EAAIuB,UAAY,EAChBvB,EAAIwB,WAAWJ,EAAGC,EAAGxJ,EAAOD,GAExBgC,EAAI+G,IAENM,EAAqBrH,GAAKoH,EAAWpH,GAAGc,OAE1Cd,IAIF,IAAMN,EAAQ0H,EAAWS,KAAI,SAACC,EAAOC,GAAR,OAAkBD,EAAM/G,WAC/CC,EAASoG,EAAWS,KAAI,SAACC,EAAOC,GAAR,OAAkBD,EAAM9G,UAEhDgH,EAAmBzC,KAAQ,WAC/B,IAAM0C,EAAiBzB,EACpB0B,KAAK,CAAClH,EAAOd,OAAQ,EAAG,IACxBiI,QAAQ,EAAE,EAAG3B,EAAa4B,MAAM,GAAI5B,EAAa4B,MAAM,GAAI,IAC9D,OAAO7C,IAAS8C,cACdJ,EACAvI,EACAsB,EACA,CAAC,IAAK,KACN,eAIEsH,EAA+B/C,KAAQ,WAC3C,OAAOrC,EAAoBqF,QAAQP,GAAkBf,eAIvDjH,EAAI,EACJC,EAAMuC,EAAmBqD,QAAQ3F,OACjC6G,EAAWK,EAAWlH,OAEtB,IADA,IAAMsI,EAAeR,EAAiBf,YAC/BjH,EAAIC,GAAK,CACd,GAAID,EAAI+G,EAAU,CAChB,IAAI0B,EAAajG,EAAmBqD,QAAQ7F,GAC5CuF,IAAWmD,SAASF,EAAaxI,GAAIyI,GAErCnB,EAA0BtH,GAAKsI,EAA6BtI,GAAG,OAC1D,CACWwC,EAAmBqD,QAAQ7F,GAAGqG,WAAW,MACjDkB,UACN,EACA,EACA/E,EAAmBqD,QAAQ7F,GAAG/B,MAC9BuE,EAAmBqD,QAAQ7F,GAAGhC,QAGlCgC,IAGFgI,EAAiB1C,eAQjB,IALAc,EAAImB,UAAU,EAAG,EAAG5C,GAAsBC,IAG1C5E,EAAI,EACJC,EAAMuC,EAAmBqD,QAAQ3F,OAC1BF,EAAIC,GAAK,CACEuC,EAAmBqD,QAAQ7F,GAAGqG,WAAW,MACjDkB,UACN,EACA,EACA/E,EAAmBqD,QAAQ7F,GAAG/B,MAC9BuE,EAAmBqD,QAAQ7F,GAAGhC,QAEhCgC,IAQJ,OAJA6C,EAAuBwE,GACvBtE,EAA4BuE,GAGrBR,KAERpF,MAAK,SAACoF,GAGL,IAFA,IAAI9G,EAAI,EACFC,EAAM6G,EAAI5G,OACTF,EAAIC,GACTsF,IAAWuB,EAAI9G,IACfA,OAGH2I,SAAQ,WACPpD,IAAWiB,GACXjB,IAAWmB,MA1MK,4CAAH,wDAyTnB,OAtGA5C,qBAAU,WACRyB,MACG7D,MAAK,SAACkH,GACLrD,MACAjE,QAAQC,IAAI,oBAEbG,KAAK2D,MACP,IAEHvB,qBAAU,WACR,GAAuB,OAAnBd,GAAmD,OAAxBE,EAA8B,CAC3D,GAAII,EAAe,CACjB,IAAMuF,EAAkBC,YACtBlD,GACA,IACA5C,EACAE,GAEF,OAAO,kBAAM6F,cAAcF,IAE3BvH,QAAQC,IAAI,mBACZqE,GAAc5C,EAAgBE,MAGjC,CACDA,EACAF,EACAmB,GACAC,GACAd,EACAF,IAGFU,qBAAU,WACR,IAAKR,EAAe,CAClB,IAAM0F,EAAM,IAAIC,MAChBD,EAAIE,IAAM/G,EACV6G,EAAIG,OAAS,WACX9F,EAAc,CACZyB,aAAckE,EAAII,cAClBvE,YAAamE,EAAIK,mBAItB,CAAC/F,IAEJQ,qBAAU,WACRjB,EAAuBJ,MA3VC,GA2V0BC,KAAK,OACvDK,EAA4BN,MA5VJ,GA4V+BC,KAAK,SAC3D,CA7VuB,IA+V1BoB,qBAAU,WACRI,IAAuBxC,MAAK,SAACE,GAC3B+B,GAAwB/B,GACpBA,EAAY1B,OAAS,GACvBuD,EAAsB7B,EAAY,SAGrC,CAAC0B,IA6CF,sBAAKgG,UAAU,MAAMC,MAAOzL,EAAOC,KAAnC,UACE,sBACEwL,MAAK,2BACAzL,EAAOQ,mBADP,IAEHkL,UAAU,GAAD,OAzZkB,GAyZlB,OAHb,UAME,sBACED,MAAK,2BACAzL,EAAOa,aADP,IAEH6K,UAAU,GAAD,OA9ZkB,GA8ZlB,OAHb,UAMGlG,GACC,sBAAKiG,MAAO,GAAZ,UACE,cAAC,IAAD,CACEE,OAAO,EACPF,MAAK,2BACAzL,EAAOiB,iBADP,IAEHf,OAAQ2G,GACR1G,MAAO2G,KAET8E,GAAG,MACHC,IAAKrH,EACLtE,OAAQ2G,GACR1G,MAAO2G,GACPgF,kBAAmB,EACnBC,iBAAiB,aACjBC,iBA3XW,CACvB9L,OAAQ,IACRC,MAAO,KACP8L,WAAY,iBA0XF,wBACEL,GAAG,WACH1L,OAAQ2G,GACR1G,MAAO2G,GACP2E,MAAK,2BACAzL,EAAOiB,iBADP,IAEHiL,OAAQ,KACR5L,gBAAiB,sBAKvBkF,GACA,sBAAKiG,MAAO,GAAZ,UACE,qBACEG,GAAG,WACHR,IAAK/G,EACLoH,MAAK,2BACAzL,EAAOiB,iBADP,IAEHf,OAAQiH,GACRhH,MAAOiH,KAETlH,OAAQiH,GACRhH,MAAOiH,GACP+E,IAAI,KAEN,wBACEP,GAAG,cACH1L,OAAQiH,GACRhH,MAAOiH,GACPqE,MAAK,2BACAzL,EAAOiB,iBADP,IAEHiL,OAAQ,KACR5L,gBAAiB,wBAM3B,qBACEmL,MAAK,2BACAzL,EAAOc,cADP,IAEH4K,UAAU,GAAD,OAAK,GAAL,OAHb,SAME,eAACU,EAAA,EAAD,WACE,eAACC,EAAA,EAAD,CAAaC,GAAI,CAAEC,EAAG,EAAGC,SAAU,KAAOC,KAAK,QAA/C,UACE,cAACC,EAAA,EAAD,CAAYd,GAAG,qCAAf,yBA1GR,cAACe,EAAA,EAAD,CACEC,QAAQ,qCACRhB,GAAG,+BACH5B,MAAOtE,EAAmB/B,SAC1BkJ,SAAU,SAACC,GACTnH,EAAsB,CACpBjC,WAAYoJ,EAAMC,OAAO7I,KACzBP,SAAUmJ,EAAMC,OAAO/C,SAG3BgD,WAAS,EACTjK,MAAM,cAXR,SAaG6C,EAAqBxD,OAAS,EAC7BwD,EAAqBmE,KAAI,SAACC,EAAOC,GAC/B,OACE,cAACgD,EAAA,EAAD,CAAsBjD,MAAOA,EAAMrG,SAAnC,SACGqG,EAAMtG,YADMuG,MAMnB,cAACgD,EAAA,EAAD,CAAUjD,MAAM,GAAhB,SAAoB,UAyFlB,cAACkD,EAAA,EAAD,CACEC,QA5HR,cAACC,EAAA,EAAD,CACEC,QAAS7H,EACTqH,SAAU,SAACC,GACTrH,EAAiBqH,EAAMC,OAAOM,UAEhCC,WAAY,CAAE,aAAc,gBAwHtBvK,MAAM,SACNwK,eAAe,kBAKvB,qBACE9B,MAAK,2BACAzL,EAAOe,eADP,IAEH2K,UAAU,GAAD,OAAK,GAAL,OAHb,SAMGhH,EAAmBqD,QAAQgC,KAAI,SAACyD,EAAMtL,GACrC,IAAIuL,EAAY,GACZC,EAAiB,GACjBC,EAAiB,GAWrB,OAT6B,OAA3B7I,EAAoB5C,SACOmF,IAA3BvC,EAAoB5C,IACY,OAAhC8C,EAAyB9C,SACOmF,IAAhCrC,EAAyB9C,KAEzBuL,EAAYzI,EAAyB9C,GAAK,EAAI,UAAY,OAC1DwL,EAAc,gBAAY5I,EAAoB5C,GAAG0L,QAAQ,IACzDD,EAAc,gBAAY3I,EAAyB9C,GAAG0L,QAAQ,KAG9D,sBAAanC,MAAOzL,EAAOgB,kBAA3B,UACE,8BAAMyM,IACN,wBACE5B,IAAK,SAACgC,GAAD,OAASnJ,EAAmBqD,QAAQ7F,GAAK2L,GAC9C3N,OAAQoH,GACRnH,MAAOmH,GACPmE,MAAO,CACLvL,OAAQoH,GACRnH,MAAOmH,MAGX,8BAAMoG,IACN,8BAAMC,MAZEzL,YCvgBP4L,EAZS,SAAAC,GAClBA,GAAeA,aAAuBC,UACxC,8BAAqBpK,MAAK,YAAkD,IAA/CqK,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOF,GACPG,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAQN,OCDdO,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFpG,SAASC,eAAe,SAM1ByF,M","file":"static/js/main.f880ce9e.chunk.js","sourcesContent":["export const styles = {\n  root: {\n    height: \"100vh\",\n    width: \"100vw\",\n    display: \"flex\",\n    alignItems: \"stretch\",\n    backgroundColor: \"#E6EE9C\",\n    flexDirection: \"column\",\n  },\n  webCamParentPanel: {\n    width: \"100%\",\n    backgroundColor: \"#C5CAE9\",\n    display: \"flex\",\n    justifyContent: \"center\",\n    alignItems: \"center\",\n    flexDirection: \"row\",\n    margin: 0,\n    padding: 0,\n    gap: 0,\n  },\n  webCamPanel: {\n    display: \"flex\",\n    height: \"100%\",\n    backgroundColor: \"#FFF59D\",\n    justifyContent: \"center\",\n    alignItems: \"center\",\n    margin: 0,\n    padding: 0,\n    gap: 0,\n  },\n  settingPanel: {\n    display: \"flex\",\n    height: \"100%\",\n    backgroundColor: \"#FFF59D\",\n    justifyContent: \"center\",\n    alignItems: \"center\",\n    margin: 0,\n    padding: 0,\n    gap: 0,\n  },\n  faceMaskPanel: {\n    display: \"flex\",\n    backgroundColor: \"#BBDEFB\",\n    justifyContent: \"space-evenly\",\n    alignItems: \"center\",\n    margin: 0,\n    padding: 0,\n    gap: 0,\n  },\n  faceMaskContainer: {\n    display: \"flex\",\n    justifyContent: \"center\",\n    alignItems: \"center\",\n    margin: 0,\n    padding: 0,\n    gap: 0,\n    flexDirection: \"column\",\n  },\n  webCamStackItem: {\n    position: \"absolute\",\n    top: 0,\n    left: 0,\n    marginLeft: \"auto\",\n  },\n};\n","import { useState, useEffect } from \"react\";\n\nfunction getWindowDimensions() {\n  //   const { innerWidth: width, innerHeight: height } = window;\n  const { width, height } = window.visualViewport;\n  return {\n    width,\n    height,\n  };\n}\n\nexport const calcExpectedWebCamDim = (\n  windowHeight,\n  windowWidth,\n  verticalPanelSplitPercentage,\n  horizontalPanelSplitPercentage,\n  webCamRatios\n) => {\n  const webCamPanelHeight = (windowHeight * verticalPanelSplitPercentage) / 100;\n  const webCamPanelWidth = (windowWidth * horizontalPanelSplitPercentage) / 100;\n  const targetWebCamHeight = webCamPanelWidth / webCamRatios[0];\n  const targetWebCamWidth = webCamPanelHeight * webCamRatios[0];\n  let expectedWebCamHeight = webCamPanelHeight;\n  let expectedWebCamWidth = webCamPanelWidth;\n  if (targetWebCamHeight > webCamPanelHeight) {\n    expectedWebCamWidth = targetWebCamWidth;\n  } else {\n    expectedWebCamHeight = targetWebCamHeight;\n  }\n\n  return {\n    webCamPanelWidth: webCamPanelWidth,\n    webCamPanelHeight: webCamPanelHeight,\n    expectedWebCamWidth: expectedWebCamWidth,\n    expectedWebCamHeight: expectedWebCamHeight,\n  };\n};\n\nexport const calcExpectedImgDim = (\n  oriImgWidth,\n  oriImgHeight,\n  webCamPanelWidth,\n  webCamPanelHeight\n) => {\n  const oriImgRatio = oriImgWidth / oriImgHeight;\n  const targetImgHeight = webCamPanelWidth / oriImgRatio;\n  const targetImgWidth = webCamPanelHeight * oriImgRatio;\n  let expectedImgHeight = webCamPanelHeight;\n  let expectedImgWidth = webCamPanelWidth;\n  if (targetImgHeight > webCamPanelHeight) {\n    expectedImgWidth = targetImgWidth;\n  } else {\n    expectedImgHeight = targetImgHeight;\n  }\n  return {\n    expectedImgWidth: expectedImgWidth,\n    expectedImgHeight: expectedImgHeight,\n  };\n};\n\nexport const buildDetectedObjects = (\n  scores,\n  threshold,\n  boxes,\n  drawHeight,\n  drawWidth,\n  captureHeight,\n  captureWidth\n) => {\n  const detectionObjects = [];\n\n  let i = 0;\n  const len = scores.length;\n  while (i < len) {\n    if (scores[i] < threshold) {\n      break;\n    }\n    const bbox = [];\n    const minY = boxes[0][i][0] * drawHeight;\n    const minX = boxes[0][i][1] * drawWidth;\n    const maxY = boxes[0][i][2] * drawHeight;\n    const maxX = boxes[0][i][3] * drawWidth;\n    bbox[0] = minX;\n    bbox[1] = minY;\n    bbox[2] = maxX - minX;\n    bbox[3] = maxY - minY;\n    // index for sliding\n    const oriMinY = parseInt(boxes[0][i][0] * captureHeight);\n    const oriMinX = parseInt(boxes[0][i][1] * captureWidth);\n    const oriMaxY = parseInt(boxes[0][i][2] * captureHeight);\n    const oriMaxX = parseInt(boxes[0][i][3] * captureWidth);\n    const slideBox = [\n      oriMinY,\n      oriMinX,\n      oriMaxY - oriMinY + 1,\n      oriMaxX - oriMinX + 1,\n    ];\n    detectionObjects.push({\n      label: \"face\",\n      score: scores[i],\n      bbox: bbox,\n      slideBox: slideBox,\n      cropBox: boxes[0][i],\n      boxInd: i,\n    });\n    i++;\n  }\n  return detectionObjects;\n};\n\nconst readImageFile = (file) => {\n  return new Promise((resolve) => {\n    const reader = new FileReader();\n\n    reader.onload = () => resolve(reader.result);\n\n    reader.readAsDataURL(file);\n  });\n};\n\nconst createHTMLImageElement = (imageSrc) => {\n  return new Promise((resolve) => {\n    const img = new Image();\n\n    img.onload = () => resolve(img);\n\n    img.src = imageSrc;\n  });\n};\n\nexport const getWebCamInfos = async () => {\n  if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {\n    console.log(\"enumerateDevices() not supported.\");\n    return [\n      {\n        deviceName: null,\n        deviceId: null,\n      },\n    ];\n  }\n  return await navigator.mediaDevices\n    .enumerateDevices()\n    .then(function (devices) {\n      let webCamInfos = [];\n      let i = 0;\n      const len = devices.length;\n      while (i < len) {\n        if (devices[i].kind === \"videoinput\") {\n          webCamInfos.push({\n            deviceName: devices[i].label,\n            deviceId: devices[i].deviceId,\n          });\n        }\n        i++;\n      }\n      return webCamInfos;\n    })\n    .catch(function (err) {\n      console.log(err.name + \": \" + err.message);\n      return [\n        {\n          deviceName: null,\n          deviceId: null,\n        },\n      ];\n    });\n};\n\n/**\n * Hooks for getting dimension of the browser window\n */\nexport function useWindowDimensions() {\n  const [windowDimensions, setWindowDimensions] = useState(\n    getWindowDimensions()\n  );\n\n  useEffect(() => {\n    function handleResize() {\n      setWindowDimensions(getWindowDimensions());\n    }\n\n    window.addEventListener(\"resize\", handleResize);\n    return () => window.removeEventListener(\"resize\", handleResize);\n  }, []);\n\n  return windowDimensions;\n}\n\n// const onCapture = async (detectionModel, classificationModel) => {\n//   if (\n//     !isUsingWebcam ||\n//     detectionModel == null ||\n//     classificationModel == null\n//   ) {\n//     return;\n//   }\n//   if (\n//     typeof webcamRef.current !== \"undefined\" &&\n//     webcamRef.current !== null &&\n//     webcamRef.current.video.readyState === 4\n//   ) {\n//     // tf.engine().startScope();\n//     /** @type {HTMLVideoElement} */\n//     const video = webcamRef.current.video;\n\n//     // Set video width\n//     webcamRef.current.video.width = expectedWebCamWidth;\n//     webcamRef.current.video.height = expectedWebCamHeight;\n\n//     const cnvs = document.getElementById(\"myCanvas\");\n//     cnvs.width = expectedWebCamWidth;\n//     cnvs.height = expectedWebCamHeight;\n\n//     const ctx = cnvs.getContext(\"2d\");\n\n//     // Font options.\n//     const font = \"16px sans-serif\";\n//     ctx.font = font;\n//     ctx.textBaseline = \"top\";\n\n//     /** @type {tf.Tensor3D} */\n//     const rawImgTensor = tf.browser.fromPixels(video);\n//     const inputTensor = tf.tidy(() => {\n//       return rawImgTensor.transpose([0, 1, 2]).expandDims();\n//     });\n//     // let startTime = performance.now();\n//     detectionModel\n//       .executeAsync(inputTensor)\n//       .then((res) => {\n//         // const a0 = res[0].arraySync(); // num_detection\n//         // const a1 = res[1].arraySync(); // raw_detection_boxes\n//         // const a2 = res[2].arraySync(); // detection_anchor_indices\n//         // const a3 = res[3].arraySync(); // raw_detection_scores\n//         // const a4 = res[4].arraySync(); // detection_boxes\n//         // const a5 = res[5].arraySync(); // detection_classes\n//         // const a6 = res[6].arraySync(); // detection_scores\n//         // const a7 = res[7].arraySync(); // detection_multiclass_scores\n//         const detection_boxes = res[4].arraySync();\n//         const detection_classes = res[5].arraySync();\n//         const detection_scores = res[6].dataSync();\n\n//         const detections = utils.buildDetectedObjects(\n//           detection_scores,\n//           0.5,\n//           detection_boxes,\n//           detection_classes,\n//           expectedWebCamHeight,\n//           expectedWebCamWidth,\n//           720,\n//           1280\n//         );\n\n//         // prepare variables\n//         let i;\n//         let len;\n//         let limitLen;\n//         const _faceDetectionScores = Array(maxNumOfDisplayFace).fill(null);\n//         const _maskClassificationScores =\n//           Array(maxNumOfDisplayFace).fill(null);\n\n//         if (detections.length > 0) {\n//           // loop for rendering bounding boxes\n//           i = 0;\n//           len = detections.length;\n//           limitLen = maxNumOfDisplayFace;\n\n//           // clear bounding box canvas\n//           ctx.clearRect(0, 0, expectedWebCamHeight, expectedWebCamWidth);\n//           while (i < len) {\n//             const x = detections[i][\"bbox\"][0];\n//             const y = detections[i][\"bbox\"][1];\n//             const width = detections[i][\"bbox\"][2];\n//             const height = detections[i][\"bbox\"][3];\n\n//             // Draw the bounding box.\n//             ctx.strokeStyle = \"#00FFFF\";\n//             ctx.lineWidth = 4;\n//             ctx.strokeRect(x, y, width, height);\n\n//             // Draw the label background.\n//             ctx.fillStyle = \"#00FFFF\";\n//             const textWidth = ctx.measureText(\n//               detections[i][\"label\"] +\n//                 \" \" +\n//                 (100 * detections[i][\"score\"]).toFixed(2) +\n//                 \"%\"\n//             ).width;\n//             const textHeight = parseInt(font, 10); // base 10\n//             ctx.fillRect(x, y, textWidth + 4, textHeight + 4);\n\n//             if (i < limitLen) {\n//               // store confidence score\n//               _faceDetectionScores[i] = detections[i].score;\n//             }\n//             i++;\n//           }\n\n//           detections.forEach((item) => {\n//             const x = item[\"bbox\"][0];\n//             const y = item[\"bbox\"][1];\n\n//             // Draw the text last to ensure it's on top.\n//             ctx.fillStyle = \"#000000\";\n//             ctx.fillText(\n//               item[\"label\"] + \" \" + (100 * item[\"score\"]).toFixed(2) + \"%\",\n//               x,\n//               y\n//             );\n//           });\n\n//           // crop resize\n//           const boxes = detections.map((value, index) => value.cropBox);\n//           const boxInd = detections.map((value, index) => value.boxInd);\n//           const stackImgTensor = tf.tidy(() => {\n//             return rawImgTensor\n//               .tile([boxInd.length, 1, 1])\n//               .reshape([-1, rawImgTensor.shape[0], rawImgTensor.shape[1], 3]);\n//           });\n\n//           const resizeImgsTensor = tf.tidy(() => {\n//             return tf.image.cropAndResize(\n//               stackImgTensor,\n//               boxes,\n//               boxInd,\n//               [224, 224],\n//               \"bilinear\"\n//             );\n//           });\n//           const _maskConfidenceScoresTensor =\n//             classificationModel.execute(resizeImgsTensor);\n//           const _allMaskClassificationScores =\n//             _maskConfidenceScoresTensor.arraySync();\n\n//           i = 0;\n//           len = multiFaceCanvasRef.current.length;\n//           limitLen = detections.length;\n//           const returnedImgs = resizeImgsTensor.arraySync();\n//           while (i < len) {\n//             if (i < limitLen) {\n//               let faceCanvas = multiFaceCanvasRef.current[i];\n//               tf.browser.toPixels(returnedImgs[i], faceCanvas);\n\n//               _maskClassificationScores[i] =\n//                 _allMaskClassificationScores[i][0];\n//             } else {\n//               const context = multiFaceCanvasRef.current[i].getContext(\"2d\");\n//               context.clearRect(\n//                 0,\n//                 0,\n//                 multiFaceCanvasRef.current[i].width,\n//                 multiFaceCanvasRef.current[i].height\n//               );\n//             }\n//             i++;\n//           }\n//           // dispose all tensor variables\n//           stackImgTensor.dispose();\n//           resizeImgsTensor.dispose();\n//           _maskConfidenceScoresTensor.dispose();\n//         } else {\n//           // clear bounding box canvas\n//           ctx.clearRect(0, 0, expectedWebCamHeight, expectedWebCamWidth);\n\n//           // clear face render canvas\n//           i = 0;\n//           len = multiFaceCanvasRef.current.length;\n//           while (i < len) {\n//             const context = multiFaceCanvasRef.current[i].getContext(\"2d\");\n//             context.clearRect(\n//               0,\n//               0,\n//               multiFaceCanvasRef.current[i].width,\n//               multiFaceCanvasRef.current[i].height\n//             );\n//             i++;\n//           }\n//         }\n\n//         setFaceDetectionScores(_faceDetectionScores);\n//         setMaskClassificationScores(_maskClassificationScores);\n//         // let endTime = performance.now();\n//         // console.log(`Took ${endTime - startTime} milliseconds`);\n//         return res;\n//       })\n//       .then((res) => {\n//         let i = 0;\n//         const len = res.length;\n//         while (i < len) {\n//           tf.dispose(res[i]);\n//           i++;\n//         }\n//       })\n//       .finally(() => {\n//         tf.dispose(rawImgTensor);\n//         tf.dispose(inputTensor);\n//       });\n//     console.log(`numTensors: ${tf.memory().numTensors}`);\n//     // tf.engine().endScope();\n//   }\n// };\n","import FormControl from \"@mui/material/FormControl\";\nimport FormControlLabel from \"@mui/material/FormControlLabel\";\nimport FormGroup from \"@mui/material/FormGroup\";\nimport InputLabel from \"@mui/material/InputLabel\";\nimport MenuItem from \"@mui/material/MenuItem\";\nimport Select from \"@mui/material/Select\";\nimport Switch from \"@mui/material/Switch\";\nimport * as tf from \"@tensorflow/tfjs\";\nimport React, { useEffect, useRef, useState } from \"react\";\nimport Webcam from \"react-webcam\";\nimport \"./App.css\";\nimport { styles } from \"./styles\";\nimport * as utils from \"./utils\";\n\nconst webCamRatios = [16 / 9, 4 / 3];\nconst verticalPanelSplitPercentage = 65;\nconst horizontalPanelSplitPercentage = 70;\nconst maxNumOfDisplayFace = 5;\n\nconst face_detection_model_url = \"tfjs/face_detection/model.json\";\nconst face_mask_classification_model_url =\n  \"tfjs/face_mask_classification/model.json\";\nconst test_img_url = `${process.env.PUBLIC_URL}/test_imgs/mask_01.jpg`;\n\nfunction App() {\n  const webcamRef = useRef(null);\n  const multiFaceCanvasRef = useRef(Array(maxNumOfDisplayFace).fill(0));\n  const [faceDetectionScores, setFaceDetectionScores] = useState([]);\n  const [maskClassificationScores, setMaskClassificationScores] = useState([]);\n  const [detectionModel, setDetectionModel] = useState(null);\n  const [classificationModel, setClassificationModel] = useState(null);\n  const [testImgDim, setTestImgDim] = useState({});\n  const [isUsingWebcam, setIsUsingWebcam] = useState(false);\n  const [selectedWebCamInfo, setSelectedWebCamInfo] = useState({\n    deviceName: \"\",\n    deviceId: \"\",\n  });\n  const [availableWebCamInfos, setAvailableWebCamInfos] = useState([]);\n  const { height: windowHeight, width: windowWidth } =\n    utils.useWindowDimensions();\n\n  const {\n    webCamPanelWidth,\n    webCamPanelHeight,\n    expectedWebCamWidth,\n    expectedWebCamHeight,\n  } = utils.calcExpectedWebCamDim(\n    windowHeight,\n    windowWidth,\n    verticalPanelSplitPercentage,\n    horizontalPanelSplitPercentage,\n    webCamRatios\n  );\n  const oriImgWidth =\n    testImgDim.oriImgWidth !== undefined ? testImgDim.oriImgWidth : 0;\n  const oriImgHeight =\n    testImgDim.oriImgHeight !== undefined ? testImgDim.oriImgHeight : 1;\n  const { expectedImgWidth, expectedImgHeight } = utils.calcExpectedImgDim(\n    oriImgWidth,\n    oriImgHeight,\n    webCamPanelWidth,\n    webCamPanelHeight\n  );\n  const faceRenderCanvasHeight =\n    ((windowHeight * (100 - verticalPanelSplitPercentage)) / 100) * 0.5;\n\n  /**\n   * generate dynamic videoConstraintsValue\n   */\n  const videoConstraints = {\n    height: 720,\n    width: 1280,\n    facingMode: \"environment\",\n    // deviceId: device.deviceId\n  };\n\n  const loadModels = async () => {\n    /** @type {tf.GraphModel} */\n    if (detectionModel !== null) {\n      detectionModel.dispose();\n    }\n    if (classificationModel !== null) {\n      classificationModel.dispose();\n    }\n    const loadedDetectionModel = await tf.loadGraphModel(\n      face_detection_model_url,\n      {\n        onProgress: (fractions) => {\n          // console.log(fractions);\n        },\n      }\n    );\n    const loadedClassificationModel = await tf.loadGraphModel(\n      face_mask_classification_model_url,\n      {\n        onProgress: (fractions) => {\n          // console.log(fractions);\n        },\n      }\n    );\n    setDetectionModel(loadedDetectionModel);\n    setClassificationModel(loadedClassificationModel);\n    console.log(\"Model loaded.\");\n    return [loadedDetectionModel, loadedClassificationModel];\n  };\n\n  const onInferencing = async (detectionModel, classificationModel) => {\n    if (detectionModel == null || classificationModel == null) {\n      return;\n    }\n    let cnvs;\n    let inputData;\n    let drawHeight;\n    let drawWidth;\n    let captureHeight;\n    let captureWidth;\n\n    // either using webcam or test image\n    if (\n      typeof webcamRef.current !== \"undefined\" &&\n      webcamRef.current !== null &&\n      webcamRef.current.video.readyState === 4\n    ) {\n      /** @type {HTMLVideoElement} */\n      inputData = webcamRef.current.video;\n      cnvs = document.getElementById(\"myCanvas\");\n\n      // Set video width\n      webcamRef.current.video.width = expectedWebCamWidth;\n      webcamRef.current.video.height = expectedWebCamHeight;\n\n      cnvs.width = expectedWebCamWidth;\n      cnvs.height = expectedWebCamHeight;\n\n      // dimension variables\n      drawHeight = expectedWebCamHeight;\n      drawWidth = expectedWebCamWidth;\n      captureHeight = 720;\n      captureWidth = 1280;\n    } else if (!isUsingWebcam) {\n      /** @type {HTMLImageElement} */\n      inputData = document.getElementById(\"test_img\");\n      cnvs = document.getElementById(\"test_canvas\");\n\n      // force resize bounding box canvas\n      cnvs.width = expectedImgWidth;\n      cnvs.height = expectedImgHeight;\n\n      // dimension variables\n      drawHeight = expectedImgHeight;\n      drawWidth = expectedImgWidth;\n      captureHeight = expectedImgHeight;\n      captureWidth = expectedImgWidth;\n    } else {\n      return;\n    }\n\n    // tf.engine().startScope();\n    const ctx = cnvs.getContext(\"2d\");\n\n    // Font options.\n    const font = \"16px sans-serif\";\n    ctx.font = font;\n    ctx.textBaseline = \"top\";\n\n    /** @type {tf.Tensor3D} */\n    const rawImgTensor = tf.browser.fromPixels(inputData);\n    const inputTensor = tf.tidy(() => {\n      return rawImgTensor.transpose([0, 1, 2]).expandDims();\n    });\n    // let startTime = performance.now();\n    detectionModel\n      .executeAsync(inputTensor)\n      .then((res) => {\n        // const a0 = res[0].arraySync(); // num_detection\n        // const a1 = res[1].arraySync(); // raw_detection_boxes\n        // const a2 = res[2].arraySync(); // detection_anchor_indices\n        // const a3 = res[3].arraySync(); // raw_detection_scores\n        // const a4 = res[4].arraySync(); // detection_boxes\n        // const a5 = res[5].arraySync(); // detection_classes\n        // const a6 = res[6].arraySync(); // detection_scores\n        // const a7 = res[7].arraySync(); // detection_multiclass_scores\n        const detection_boxes = res[4].arraySync();\n        const detection_scores = res[6].dataSync();\n\n        const detections = utils.buildDetectedObjects(\n          detection_scores,\n          0.5,\n          detection_boxes,\n          drawHeight,\n          drawWidth,\n          captureHeight,\n          captureWidth\n        );\n\n        // prepare variables\n        let i;\n        let len;\n        let limitLen;\n        const _faceDetectionScores = Array(maxNumOfDisplayFace).fill(null);\n        const _maskClassificationScores = Array(maxNumOfDisplayFace).fill(null);\n\n        if (detections.length > 0) {\n          // loop for rendering bounding boxes\n          i = 0;\n          len = detections.length;\n          limitLen = maxNumOfDisplayFace;\n\n          // clear bounding box canvas\n          ctx.clearRect(0, 0, expectedWebCamHeight, expectedWebCamWidth);\n          while (i < len) {\n            const x = detections[i][\"bbox\"][0];\n            const y = detections[i][\"bbox\"][1];\n            const width = detections[i][\"bbox\"][2];\n            const height = detections[i][\"bbox\"][3];\n\n            // Draw the bounding box.\n            ctx.strokeStyle = \"#00FFFF\";\n            ctx.lineWidth = 2;\n            ctx.strokeRect(x, y, width, height);\n\n            if (i < limitLen) {\n              // store confidence score\n              _faceDetectionScores[i] = detections[i].score;\n            }\n            i++;\n          }\n\n          // crop resize\n          const boxes = detections.map((value, index) => value.cropBox);\n          const boxInd = detections.map((value, index) => value.boxInd);\n\n          const resizeImgsTensor = tf.tidy(() => {\n            const stackImgTensor = rawImgTensor\n              .tile([boxInd.length, 1, 1])\n              .reshape([-1, rawImgTensor.shape[0], rawImgTensor.shape[1], 3]);\n            return tf.image.cropAndResize(\n              stackImgTensor,\n              boxes,\n              boxInd,\n              [224, 224],\n              \"bilinear\"\n            );\n          });\n\n          const _allMaskClassificationScores = tf.tidy(() => {\n            return classificationModel.execute(resizeImgsTensor).arraySync();\n          });\n\n          // render faces\n          i = 0;\n          len = multiFaceCanvasRef.current.length;\n          limitLen = detections.length;\n          const returnedImgs = resizeImgsTensor.arraySync();\n          while (i < len) {\n            if (i < limitLen) {\n              let faceCanvas = multiFaceCanvasRef.current[i];\n              tf.browser.toPixels(returnedImgs[i], faceCanvas);\n\n              _maskClassificationScores[i] = _allMaskClassificationScores[i][0];\n            } else {\n              const context = multiFaceCanvasRef.current[i].getContext(\"2d\");\n              context.clearRect(\n                0,\n                0,\n                multiFaceCanvasRef.current[i].width,\n                multiFaceCanvasRef.current[i].height\n              );\n            }\n            i++;\n          }\n          // dispose all tensor variables\n          resizeImgsTensor.dispose();\n        } else {\n          // clear bounding box canvas\n          ctx.clearRect(0, 0, expectedWebCamHeight, expectedWebCamWidth);\n\n          // clear face render canvas\n          i = 0;\n          len = multiFaceCanvasRef.current.length;\n          while (i < len) {\n            const context = multiFaceCanvasRef.current[i].getContext(\"2d\");\n            context.clearRect(\n              0,\n              0,\n              multiFaceCanvasRef.current[i].width,\n              multiFaceCanvasRef.current[i].height\n            );\n            i++;\n          }\n        }\n\n        setFaceDetectionScores(_faceDetectionScores);\n        setMaskClassificationScores(_maskClassificationScores);\n        // let endTime = performance.now();\n        // console.log(`Took ${endTime - startTime} milliseconds`);\n        return res;\n      })\n      .then((res) => {\n        let i = 0;\n        const len = res.length;\n        while (i < len) {\n          tf.dispose(res[i]);\n          i++;\n        }\n      })\n      .finally(() => {\n        tf.dispose(rawImgTensor);\n        tf.dispose(inputTensor);\n      });\n    // console.log(`numTensors: ${tf.memory().numTensors}`);\n    // tf.engine().endScope();\n  };\n\n  /* \n    Run only once\n     */\n  useEffect(() => {\n    tf.ready()\n      .then((_) => {\n        tf.enableProdMode();\n        console.log(\"tfjs is ready\");\n      })\n      .then(loadModels);\n  }, []);\n\n  useEffect(() => {\n    if (detectionModel !== null && classificationModel !== null) {\n      if (isUsingWebcam) {\n        const captureInterval = setInterval(\n          onInferencing,\n          100,\n          detectionModel,\n          classificationModel\n        );\n        return () => clearInterval(captureInterval);\n      } else {\n        console.log(\"Run on test img\");\n        onInferencing(detectionModel, classificationModel);\n      }\n    }\n  }, [\n    classificationModel,\n    detectionModel,\n    windowHeight,\n    windowWidth,\n    isUsingWebcam,\n    testImgDim,\n  ]);\n\n  useEffect(() => {\n    if (!isUsingWebcam) {\n      const img = new Image();\n      img.src = test_img_url;\n      img.onload = () => {\n        setTestImgDim({\n          oriImgHeight: img.naturalHeight,\n          oriImgWidth: img.naturalWidth,\n        });\n      };\n    }\n  }, [isUsingWebcam]);\n\n  useEffect(() => {\n    setFaceDetectionScores(Array(maxNumOfDisplayFace).fill(null));\n    setMaskClassificationScores(Array(maxNumOfDisplayFace).fill(null));\n  }, [maxNumOfDisplayFace]);\n\n  useEffect(() => {\n    utils.getWebCamInfos().then((webCamInfos) => {\n      setAvailableWebCamInfos(webCamInfos);\n      if (webCamInfos.length > 0) {\n        setSelectedWebCamInfo(webCamInfos[0]);\n      }\n    });\n  }, [isUsingWebcam]);\n\n  const webCamToggle = () => {\n    return (\n      <Switch\n        checked={isUsingWebcam}\n        onChange={(event) => {\n          setIsUsingWebcam(event.target.checked);\n        }}\n        inputProps={{ \"aria-label\": \"controlled\" }}\n      />\n    );\n  };\n\n  const videoInputSelector = () => {\n    return (\n      <Select\n        labelId=\"demo-simple-select-autowidth-label\"\n        id=\"demo-simple-select-autowidth\"\n        value={selectedWebCamInfo.deviceId}\n        onChange={(event) => {\n          setSelectedWebCamInfo({\n            deviceName: event.target.name,\n            deviceId: event.target.value,\n          });\n        }}\n        autoWidth\n        label=\"Video Input\"\n      >\n        {availableWebCamInfos.length > 0 ? (\n          availableWebCamInfos.map((value, index) => {\n            return (\n              <MenuItem key={index} value={value.deviceId}>\n                {value.deviceName}\n              </MenuItem>\n            );\n          })\n        ) : (\n          <MenuItem value=\"\">{\"\"}</MenuItem>\n        )}\n      </Select>\n    );\n  };\n\n  return (\n    <div className=\"App\" style={styles.root}>\n      <div\n        style={{\n          ...styles.webCamParentPanel,\n          flexBasis: `${verticalPanelSplitPercentage}%`,\n        }}\n      >\n        <div\n          style={{\n            ...styles.webCamPanel,\n            flexBasis: `${horizontalPanelSplitPercentage}%`,\n          }}\n        >\n          {isUsingWebcam && (\n            <div style={{}}>\n              <Webcam\n                audio={false}\n                style={{\n                  ...styles.webCamStackItem,\n                  height: expectedWebCamHeight,\n                  width: expectedWebCamWidth,\n                }}\n                id=\"img\"\n                ref={webcamRef}\n                height={expectedWebCamHeight}\n                width={expectedWebCamWidth}\n                screenshotQuality={1}\n                screenshotFormat=\"image/jpeg\"\n                videoConstraints={videoConstraints}\n              />\n              <canvas\n                id=\"myCanvas\"\n                height={expectedWebCamHeight}\n                width={expectedWebCamWidth}\n                style={{\n                  ...styles.webCamStackItem,\n                  zIndex: 9999,\n                  backgroundColor: \"transparent\",\n                }}\n              />\n            </div>\n          )}\n          {!isUsingWebcam && (\n            <div style={{}}>\n              <img\n                id=\"test_img\"\n                src={test_img_url}\n                style={{\n                  ...styles.webCamStackItem,\n                  height: expectedImgHeight,\n                  width: expectedImgWidth,\n                }}\n                height={expectedImgHeight}\n                width={expectedImgWidth}\n                alt=\"\"\n              />\n              <canvas\n                id=\"test_canvas\"\n                height={expectedImgHeight}\n                width={expectedImgWidth}\n                style={{\n                  ...styles.webCamStackItem,\n                  zIndex: 9999,\n                  backgroundColor: \"transparent\",\n                }}\n              />\n            </div>\n          )}\n        </div>\n        <div\n          style={{\n            ...styles.settingPanel,\n            flexBasis: `${100 - horizontalPanelSplitPercentage}%`,\n          }}\n        >\n          <FormGroup>\n            <FormControl sx={{ m: 1, minWidth: 220 }} size=\"small\">\n              <InputLabel id=\"demo-simple-select-autowidth-label\">\n                Video Input\n              </InputLabel>\n              {videoInputSelector()}\n            </FormControl>\n            <FormControlLabel\n              control={webCamToggle()}\n              label=\"Webcam\"\n              labelPlacement=\"start\"\n            />\n          </FormGroup>\n        </div>\n      </div>\n      <div\n        style={{\n          ...styles.faceMaskPanel,\n          flexBasis: `${100 - verticalPanelSplitPercentage}%`,\n        }}\n      >\n        {multiFaceCanvasRef.current.map((item, i) => {\n          let labelName = \"\";\n          let faceScoreLabel = \"\";\n          let maskScoreLabel = \"\";\n          if (\n            faceDetectionScores[i] !== null &&\n            faceDetectionScores[i] !== undefined &&\n            maskClassificationScores[i] !== null &&\n            maskClassificationScores[i] !== undefined\n          ) {\n            labelName = maskClassificationScores[i] > 0 ? \"No Mask\" : \"Mask\";\n            faceScoreLabel = `Face: ${faceDetectionScores[i].toFixed(2)}`;\n            maskScoreLabel = `Mask: ${maskClassificationScores[i].toFixed(2)}`;\n          }\n          return (\n            <div key={i} style={styles.faceMaskContainer}>\n              <div>{labelName}</div>\n              <canvas\n                ref={(el) => (multiFaceCanvasRef.current[i] = el)}\n                height={faceRenderCanvasHeight}\n                width={faceRenderCanvasHeight}\n                style={{\n                  height: faceRenderCanvasHeight,\n                  width: faceRenderCanvasHeight,\n                }}\n              />\n              <div>{faceScoreLabel}</div>\n              <div>{maskScoreLabel}</div>\n            </div>\n          );\n        })}\n      </div>\n    </div>\n  );\n}\n\nexport default App;\n","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}