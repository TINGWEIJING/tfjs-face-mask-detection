{"version":3,"sources":["styles.js","utils.js","App.js","reportWebVitals.js","index.js"],"names":["styles","root","height","width","display","alignItems","backgroundColor","flexDirection","webCamParentPanel","justifyContent","margin","padding","gap","webCamPanel","settingPanel","faceMaskPanel","faceMaskContainer","webCamStackItem","position","top","left","marginLeft","getWindowDimensions","window","visualViewport","buildDetectedObjects","scores","threshold","boxes","drawHeight","drawWidth","captureHeight","captureWidth","detectionObjects","i","len","length","bbox","minY","minX","maxY","maxX","oriMinY","parseInt","oriMinX","slideBox","push","label","score","cropBox","boxInd","getWebCamInfos","a","navigator","mediaDevices","enumerateDevices","console","log","deviceName","deviceId","then","devices","webCamInfos","kind","catch","err","name","message","webCamRatios","test_img_url","process","App","webcamRef","useRef","multiFaceCanvasRef","Array","fill","useState","faceDetectorProgress","setFaceDetectorProgress","maskClassifierProgress","setMaskClassifierProgress","faceDetectionScores","setFaceDetectionScores","maskClassificationScores","setMaskClassificationScores","detectionModel","setDetectionModel","classificationModel","setClassificationModel","testImgDim","setTestImgDim","isUsingWebcam","setIsUsingWebcam","selectedWebCamInfo","setSelectedWebCamInfo","availableWebCamInfos","setAvailableWebCamInfos","windowDimensions","setWindowDimensions","useEffect","handleResize","addEventListener","removeEventListener","utils","windowHeight","windowWidth","verticalPanelSplitPercentage","horizontalPanelSplitPercentage","webCamPanelHeight","webCamPanelWidth","targetWebCamHeight","targetWebCamWidth","expectedWebCamHeight","expectedWebCamWidth","oriImgWidth","oriImgHeight","oriImgRatio","targetImgHeight","expectedImgHeight","expectedImgWidth","undefined","faceRenderCanvasHeight","videoConstraints","loadModels","dispose","tf","onProgress","fractions","loadedDetectionModel","loadedClassificationModel","onInferencing","current","video","readyState","inputData","cnvs","document","getElementById","ctx","getContext","font","textBaseline","rawImgTensor","fromPixels","inputTensor","transpose","expandDims","executeAsync","res","limitLen","detection_boxes","arraySync","detection_scores","dataSync","detections","_faceDetectionScores","_maskClassificationScores","clearRect","x","y","strokeStyle","lineWidth","strokeRect","map","value","index","resizeImgsTensor","stackImgTensor","tile","reshape","shape","cropAndResize","_allMaskClassificationScores","execute","returnedImgs","faceCanvas","toPixels","finally","_","captureInterval","setInterval","clearInterval","img","Image","src","onload","naturalHeight","naturalWidth","className","style","flexBasis","audio","id","ref","screenshotQuality","screenshotFormat","zIndex","alt","FormGroup","FormControl","sx","m","minWidth","size","InputLabel","Select","labelId","onChange","event","target","autoWidth","MenuItem","FormControlLabel","control","Switch","checked","inputProps","labelPlacement","faceDetectionModelProgress","maskClassifierModelProgress","item","labelName","faceScoreLabel","maskScoreLabel","toFixed","el","reportWebVitals","onPerfEntry","Function","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode"],"mappings":"+gBAAaA,G,OAAS,CACpBC,KAAM,CACJC,OAAQ,QACRC,MAAO,QACPC,QAAS,OACTC,WAAY,UACZC,gBAAiB,UACjBC,cAAe,UAEjBC,kBAAmB,CACjBL,MAAO,OACPG,gBAAiB,UACjBF,QAAS,OACTK,eAAgB,SAChBJ,WAAY,SACZE,cAAe,MACfG,OAAQ,EACRC,QAAS,EACTC,IAAK,GAEPC,YAAa,CACXT,QAAS,OACTF,OAAQ,OACRI,gBAAiB,UACjBG,eAAgB,SAChBJ,WAAY,SACZK,OAAQ,EACRC,QAAS,EACTC,IAAK,GAEPE,aAAc,CACZV,QAAS,OACTF,OAAQ,OACRI,gBAAiB,UACjBG,eAAgB,SAChBJ,WAAY,SACZK,OAAQ,EACRC,QAAS,EACTC,IAAK,GAEPG,cAAe,CACbX,QAAS,OACTE,gBAAiB,UACjBG,eAAgB,eAChBJ,WAAY,SACZK,OAAQ,EACRC,QAAS,EACTC,IAAK,GAEPI,kBAAmB,CACjBZ,QAAS,OACTK,eAAgB,SAChBJ,WAAY,SACZK,OAAQ,EACRC,QAAS,EACTC,IAAK,EACLL,cAAe,UAEjBU,gBAAiB,CACfC,SAAU,WACVC,IAAK,EACLC,KAAM,EACNC,WAAY,UC5DhB,SAASC,IAEP,MAA0BC,OAAOC,eACjC,MAAO,CACLrB,MAFF,EAAQA,MAGND,OAHF,EAAeA,QAOV,IAiDMuB,EAAuB,SAClCC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,GAMA,IAJA,IAAMC,EAAmB,GAErBC,EAAI,EACFC,EAAMT,EAAOU,OACZF,EAAIC,KACLT,EAAOQ,GAAKP,IADF,CAId,IAAMU,EAAO,GACPC,EAAOV,EAAM,GAAGM,GAAG,GAAKL,EACxBU,EAAOX,EAAM,GAAGM,GAAG,GAAKJ,EACxBU,EAAOZ,EAAM,GAAGM,GAAG,GAAKL,EACxBY,EAAOb,EAAM,GAAGM,GAAG,GAAKJ,EAC9BO,EAAK,GAAKE,EACVF,EAAK,GAAKC,EACVD,EAAK,GAAKI,EAAOF,EACjBF,EAAK,GAAKG,EAAOF,EAEjB,IAAMI,EAAUC,SAASf,EAAM,GAAGM,GAAG,GAAKH,GACpCa,EAAUD,SAASf,EAAM,GAAGM,GAAG,GAAKF,GAGpCa,EAAW,CACfH,EACAE,EAJcD,SAASf,EAAM,GAAGM,GAAG,GAAKH,GAK9BW,EAAU,EAJNC,SAASf,EAAM,GAAGM,GAAG,GAAKF,GAK9BY,EAAU,GAEtBX,EAAiBa,KAAK,CACpBC,MAAO,OACPC,MAAOtB,EAAOQ,GACdG,KAAMA,EACNQ,SAAUA,EACVI,QAASrB,EAAM,GAAGM,GAClBgB,OAAQhB,IAEVA,IAEF,OAAOD,GAuBIkB,EAAc,uCAAG,sBAAAC,EAAA,yDACvBC,UAAUC,cAAiBD,UAAUC,aAAaC,iBAD3B,uBAE1BC,QAAQC,IAAI,qCAFc,kBAGnB,CACL,CACEC,WAAY,KACZC,SAAU,QANY,uBAUfN,UAAUC,aACpBC,mBACAK,MAAK,SAAUC,GAId,IAHA,IAAIC,EAAc,GACd5B,EAAI,EACFC,EAAM0B,EAAQzB,OACbF,EAAIC,GACe,eAApB0B,EAAQ3B,GAAG6B,MACbD,EAAYhB,KAAK,CACfY,WAAYG,EAAQ3B,GAAGa,MACvBY,SAAUE,EAAQ3B,GAAGyB,WAGzBzB,IAEF,OAAO4B,KAERE,OAAM,SAAUC,GAEf,OADAT,QAAQC,IAAIQ,EAAIC,KAAO,KAAOD,EAAIE,SAC3B,CACL,CACET,WAAY,KACZC,SAAU,UAhCU,mFAAH,qD,YCpHrBS,EAAe,CAAC,GAAK,EAAG,EAAI,GAQ5BC,EAAY,UAAMC,4BAAN,0BA2iBHC,MAziBf,WACE,IAAMC,EAAYC,iBAAO,MACnBC,EAAqBD,iBAAOE,MATR,GASmCC,KAAK,IAClE,EAAwDC,mBAAS,GAAjE,mBAAOC,EAAP,KAA6BC,EAA7B,KACA,EAA4DF,mBAAS,GAArE,mBAAOG,EAAP,KAA+BC,EAA/B,KACA,EAAsDJ,mBAAS,IAA/D,mBAAOK,EAAP,KAA4BC,EAA5B,KACA,EAAgEN,mBAAS,IAAzE,mBAAOO,EAAP,KAAiCC,EAAjC,KACA,EAA4CR,mBAAS,MAArD,mBAAOS,EAAP,KAAuBC,EAAvB,KACA,EAAsDV,mBAAS,MAA/D,mBAAOW,EAAP,KAA4BC,EAA5B,KACA,EAAoCZ,mBAAS,IAA7C,mBAAOa,EAAP,KAAmBC,EAAnB,KACA,EAA0Cd,oBAAS,GAAnD,mBAAOe,EAAP,KAAsBC,GAAtB,KACA,GAAoDhB,mBAAS,CAC3DnB,WAAY,GACZC,SAAU,KAFZ,qBAAOmC,GAAP,MAA2BC,GAA3B,MAIA,GAAwDlB,mBAAS,IAAjE,qBAAOmB,GAAP,MAA6BC,GAA7B,MACA,GDmIK,WACL,MAAgDpB,mBAC9CvD,KADF,mBAAO4E,EAAP,KAAyBC,EAAzB,KAaA,OATAC,qBAAU,WACR,SAASC,IACPF,EAAoB7E,KAItB,OADAC,OAAO+E,iBAAiB,SAAUD,GAC3B,kBAAM9E,OAAOgF,oBAAoB,SAAUF,MACjD,IAEIH,EChJLM,GADcC,GAAhB,GAAQvG,OAA6BwG,GAArC,GAA8BvG,MAG9B,GDhCmC,SACnCsG,EACAC,EACAC,EACAC,EACAxC,GAEA,IAAMyC,EAAqBJ,EAAeE,EAAgC,IACpEG,EAAoBJ,EAAcE,EAAkC,IACpEG,EAAqBD,EAAmB1C,EAAa,GACrD4C,EAAoBH,EAAoBzC,EAAa,GACvD6C,EAAuBJ,EACvBK,EAAsBJ,EAO1B,OANIC,EAAqBF,EACvBK,EAAsBF,EAEtBC,EAAuBF,EAGlB,CACLD,iBAAkBA,EAClBD,kBAAmBA,EACnBK,oBAAqBA,EACrBD,qBAAsBA,GCcpBT,CACFC,GACAC,GAnCiC,GACE,GAqCnCtC,GATA0C,GADF,GACEA,iBACAD,GAFF,GAEEA,kBACAK,GAHF,GAGEA,oBACAD,GAJF,GAIEA,qBAYF,GDrBgC,SAChCE,EACAC,EACAN,EACAD,GAEA,IAAMQ,EAAcF,EAAcC,EAC5BE,EAAkBR,EAAmBO,EAEvCE,EAAoBV,EACpBW,EAAmBV,EAMvB,OALIQ,EAAkBT,EACpBW,EAJqBX,EAAoBQ,EAMzCE,EAAoBD,EAEf,CACLE,iBAAkBA,EAClBD,kBAAmBA,GCG2Bf,MAHnBiB,IAA3B/B,EAAWyB,YAA4BzB,EAAWyB,YAAc,OAEpCM,IAA5B/B,EAAW0B,aAA6B1B,EAAW0B,aAAe,EAIlEN,GACAD,IAJMW,GAAR,GAAQA,iBAAkBD,GAA1B,GAA0BA,kBAMpBG,GACU,GAAZjB,GAAuD,IAAO,GAK5DkB,GAAmB,CACvBzH,OAAQ,IACRC,MAAO,KAEPwD,SAAUmC,GAAmBnC,UAGzBiE,GAAU,uCAAG,8BAAAxE,EAAA,6DAEM,OAAnBkC,GACFA,EAAeuC,UAEW,OAAxBrC,GACFA,EAAoBqC,UANL,SAQkBC,IAnEN,iCAqE3B,CACEC,WAAY,SAACC,GACXjD,EAAwBiD,MAZb,cAQXC,EARW,gBAiBuBH,IA1E1C,2CA4EI,CACEC,WAAY,SAACC,GACX/C,EAA0B+C,MArBf,cAiBXE,EAjBW,OA0BjB3C,EAAkB0C,GAClBxC,EAAuByC,GACvB1E,QAAQC,IAAI,iBA5BK,kBA6BV,CAACwE,EAAsBC,IA7Bb,4CAAH,qDAgCVC,GAAa,uCAAG,WAAO7C,EAAgBE,GAAvB,+BAAApC,EAAA,yDACE,MAAlBkC,GAAiD,MAAvBE,EADV,oDAaW,qBAAtBhB,EAAU4D,SACK,OAAtB5D,EAAU4D,SAC6B,IAAvC5D,EAAU4D,QAAQC,MAAMC,WAfN,iBAkBlBC,EAAY/D,EAAU4D,QAAQC,MAC9BG,EAAOC,SAASC,eAAe,YAG/BlE,EAAU4D,QAAQC,MAAMlI,MAAQ+G,GAChC1C,EAAU4D,QAAQC,MAAMnI,OAAS+G,GAEjCuB,EAAKrI,MAAQ+G,GACbsB,EAAKtI,OAAS+G,GAGdpF,EAAaoF,GACbnF,EAAYoF,GACZnF,EAAgB,IAChBC,EAAe,KAhCG,2BAiCR4D,EAjCQ,iBAmClB2C,EAAYE,SAASC,eAAe,aACpCF,EAAOC,SAASC,eAAe,gBAG1BvI,MAAQqH,GACbgB,EAAKtI,OAASqH,GAGd1F,EAAa0F,GACbzF,EAAY0F,GACZzF,EAAgBwF,GAChBvF,EAAewF,GA9CG,0DAoDdmB,EAAMH,EAAKI,WAAW,MAGf,kBACbD,EAAIE,KADS,kBAEbF,EAAIG,aAAe,MAGbC,EAAejB,IAAWkB,WAAWT,GACrCU,EAAcnB,KAAQ,WAC1B,OAAOiB,EAAaG,UAAU,CAAC,EAAG,EAAG,IAAIC,gBAG3C7D,EACG8D,aAAaH,GACbrF,MAAK,SAACyF,GASL,IAcInH,EACAC,EACAmH,EAhBEC,EAAkBF,EAAI,GAAGG,YACzBC,EAAmBJ,EAAI,GAAGK,WAE1BC,EAAanD,EACjBiD,EACA,GACAF,EACA1H,EACAC,EACAC,EACAC,GAOI4H,EAAuBjF,MA1LT,GA0LoCC,KAAK,MACvDiF,EAA4BlF,MA3Ld,GA2LyCC,KAAK,MAElE,GAAI+E,EAAWvH,OAAS,EAAG,CAQzB,IANAF,EAAI,EACJC,EAAMwH,EAAWvH,OACjBkH,EAjMkB,EAoMlBX,EAAImB,UAAU,EAAG,EAAG7C,GAAsBC,IACnChF,EAAIC,GAAK,CACd,IAAM4H,EAAIJ,EAAWzH,GAAX,KAAsB,GAC1B8H,EAAIL,EAAWzH,GAAX,KAAsB,GAC1B/B,EAAQwJ,EAAWzH,GAAX,KAAsB,GAC9BhC,EAASyJ,EAAWzH,GAAX,KAAsB,GAGrCyG,EAAIsB,YAAc,UAClBtB,EAAIuB,UAAY,EAChBvB,EAAIwB,WAAWJ,EAAGC,EAAG7J,EAAOD,GAExBgC,EAAIoH,IAENM,EAAqB1H,GAAKyH,EAAWzH,GAAGc,OAE1Cd,IAIF,IAAMN,EAAQ+H,EAAWS,KAAI,SAACC,EAAOC,GAAR,OAAkBD,EAAMpH,WAC/CC,EAASyG,EAAWS,KAAI,SAACC,EAAOC,GAAR,OAAkBD,EAAMnH,UAEhDqH,EAAmBzC,KAAQ,WAC/B,IAAM0C,EAAiBzB,EACpB0B,KAAK,CAACvH,EAAOd,OAAQ,EAAG,IACxBsI,QAAQ,EAAE,EAAG3B,EAAa4B,MAAM,GAAI5B,EAAa4B,MAAM,GAAI,IAC9D,OAAO7C,IAAS8C,cACdJ,EACA5I,EACAsB,EACA,CAAC,IAAK,KACN,eAIE2H,EAA+B/C,KAAQ,WAC3C,OAAOtC,EAAoBsF,QAAQP,GAAkBf,eAIvDtH,EAAI,EACJC,EAAMuC,EAAmB0D,QAAQhG,OACjCkH,EAAWK,EAAWvH,OAEtB,IADA,IAAM2I,EAAeR,EAAiBf,YAC/BtH,EAAIC,GAAK,CACd,GAAID,EAAIoH,EAAU,CAChB,IAAI0B,EAAatG,EAAmB0D,QAAQlG,GAC5C4F,IAAWmD,SAASF,EAAa7I,GAAI8I,GAErCnB,EAA0B3H,GAAK2I,EAA6B3I,GAAG,OAC1D,CACWwC,EAAmB0D,QAAQlG,GAAG0G,WAAW,MACjDkB,UACN,EACA,EACApF,EAAmB0D,QAAQlG,GAAG/B,MAC9BuE,EAAmB0D,QAAQlG,GAAGhC,QAGlCgC,IAGFqI,EAAiB1C,eAQjB,IALAc,EAAImB,UAAU,EAAG,EAAG7C,GAAsBC,IAG1ChF,EAAI,EACJC,EAAMuC,EAAmB0D,QAAQhG,OAC1BF,EAAIC,GAAK,CACEuC,EAAmB0D,QAAQlG,GAAG0G,WAAW,MACjDkB,UACN,EACA,EACApF,EAAmB0D,QAAQlG,GAAG/B,MAC9BuE,EAAmB0D,QAAQlG,GAAGhC,QAEhCgC,IAQJ,OAJAiD,EAAuByE,GACvBvE,EAA4BwE,GAGrBR,KAERzF,MAAK,SAACyF,GAGL,IAFA,IAAInH,EAAI,EACFC,EAAMkH,EAAIjH,OACTF,EAAIC,GACT2F,IAAWuB,EAAInH,IACfA,OAGHgJ,SAAQ,WACPpD,IAAWiB,GACXjB,IAAWmB,MA1MK,4CAAH,wDA4WnB,OAzJA7C,qBAAU,WACR0B,MACGlE,MAAK,SAACuH,GACLrD,MACAtE,QAAQC,IAAI,oBAEbG,KAAKgE,MACP,IAEHxB,qBAAU,WACR,GAAuB,OAAnBd,GAAmD,OAAxBE,EAA8B,CAC3D,GAAII,EAAe,CACjB,IAAMwF,EAAkBC,YACtBlD,GACA,IACA7C,EACAE,GAEF,OAAO,kBAAM8F,cAAcF,IAE3B5H,QAAQC,IAAI,mBACZ0E,GAAc7C,EAAgBE,MAGjC,CACDA,EACAF,EACAmB,GACAC,GACAd,EACAF,IAGFU,qBAAU,WACR,IAAKR,EAAe,CAClB,IAAM2F,EAAM,IAAIC,MAChBD,EAAIE,IAAMpH,EACVkH,EAAIG,OAAS,WACX/F,EAAc,CACZyB,aAAcmE,EAAII,cAClBxE,YAAaoE,EAAIK,mBAItB,CAAChG,IAEJQ,qBAAU,WACRjB,EAAuBR,MA/VC,GA+V0BC,KAAK,OACvDS,EAA4BV,MAhWJ,GAgW+BC,KAAK,SAC3D,CAjWuB,IAmW1BwB,qBAAU,WACRI,IAAuB5C,MAAK,SAACE,GAC3BmC,GAAwBnC,GACpBA,EAAY1B,OAAS,GACvB2D,GAAsBjC,EAAY,SAGrC,CAAC8B,IAgGF,sBAAKiG,UAAU,MAAMC,MAAO9L,EAAOC,KAAnC,UACE,sBACE6L,MAAK,2BACA9L,EAAOQ,mBADP,IAEHuL,UAAU,GAAD,OAhdkB,GAgdlB,OAHb,UAME,sBACED,MAAK,2BACA9L,EAAOa,aADP,IAEHkL,UAAU,GAAD,OArdkB,GAqdlB,OAHb,UAMGnG,GACC,sBAAKkG,MAAO,GAAZ,UACE,cAAC,IAAD,CACEE,OAAO,EACPF,MAAK,2BACA9L,EAAOiB,iBADP,IAEHf,OAAQ+G,GACR9G,MAAO+G,KAET+E,GAAG,MACHC,IAAK1H,EACLtE,OAAQ+G,GACR9G,MAAO+G,GACPiF,kBAAmB,EACnBC,iBAAiB,aACjBzE,iBAAkBA,KAEpB,wBACEsE,GAAG,WACH/L,OAAQ+G,GACR9G,MAAO+G,GACP4E,MAAK,2BACA9L,EAAOiB,iBADP,IAEHoL,OAAQ,KACR/L,gBAAiB,sBAKvBsF,GACA,sBAAKkG,MAAO,GAAZ,UACE,qBACEG,GAAG,WACHR,IAAKpH,EACLyH,MAAK,2BACA9L,EAAOiB,iBADP,IAEHf,OAAQqH,GACRpH,MAAOqH,KAETtH,OAAQqH,GACRpH,MAAOqH,GACP8E,IAAI,KAEN,wBACEL,GAAG,cACH/L,OAAQqH,GACRpH,MAAOqH,GACPsE,MAAK,2BACA9L,EAAOiB,iBADP,IAEHoL,OAAQ,KACR/L,gBAAiB,wBAM3B,qBACEwL,MAAK,2BACA9L,EAAOc,cADP,IAEHiL,UAAU,GAAD,OAAK,GAAL,OAHb,SAME,eAACQ,EAAA,EAAD,WACE,eAACC,EAAA,EAAD,CAAaC,GAAI,CAAEC,EAAG,EAAGC,SAAU,KAAOC,KAAK,QAA/C,UACE,cAACC,EAAA,EAAD,CAAYZ,GAAG,qCAAf,yBA7JR,cAACa,EAAA,EAAD,CACEC,QAAQ,qCACRd,GAAG,+BACH5B,MAAOvE,GAAmBnC,SAC1BqJ,SAAU,SAACC,GACTlH,GAAsB,CACpBrC,WAAYuJ,EAAMC,OAAOhJ,KACzBP,SAAUsJ,EAAMC,OAAO7C,SAG3B8C,WAAS,EACTpK,MAAM,cAXR,SAaGiD,GAAqB5D,OAAS,EAC7B4D,GAAqBoE,KAAI,SAACC,EAAOC,GAC/B,OACE,cAAC8C,EAAA,EAAD,CAAsB/C,MAAOA,EAAM1G,SAAnC,SACG0G,EAAM3G,YADM4G,MAMnB,cAAC8C,EAAA,EAAD,CAAU/C,MAAM,GAAhB,SAAoB,UA4IlB,cAACgD,EAAA,EAAD,CACEC,QA/KR,cAACC,EAAA,EAAD,CACEC,QAAS5H,EACToH,SAAU,SAACC,GACTpH,GAAiBoH,EAAMC,OAAOM,UAEhCC,WAAY,CAAE,aAAc,gBA2KtB1K,MAAM,SACN2K,eAAe,kBAKvB,qBACE5B,MAAK,2BACA9L,EAAOe,eADP,IAEHgL,UAAU,GAAD,OAAK,GAAL,OAHb,SA9IkB,WACpB,GAAsB,MAAlBzG,GAAiD,MAAvBE,EAA6B,CACzD,IAAMmI,EAA0B,iCACP,IAAvB7I,EAD8B,KAG1B8I,EAA2B,kCACN,IAAzB5I,EAD+B,KAGjC,OACE,gCACE,8BAAM,2BACN,8BAAM2I,IACN,8BAAMC,OAGL,OAAIlJ,EAAmB0D,QAAQhG,OAAS,EACtC,8BAAM,mBAERsC,EAAmB0D,QAAQgC,KAAI,SAACyD,EAAM3L,GAC3C,IAAI4L,EAAY,GACZC,EAAiB,GACjBC,EAAiB,GAWrB,OAT6B,OAA3B9I,EAAoBhD,SACOuF,IAA3BvC,EAAoBhD,IACY,OAAhCkD,EAAyBlD,SACOuF,IAAhCrC,EAAyBlD,KAEzB4L,EAAY1I,EAAyBlD,GAAK,EAAI,UAAY,OAC1D6L,EAAc,gBAAY7I,EAAoBhD,GAAG+L,QAAQ,IACzDD,EAAc,gBAAY5I,EAAyBlD,GAAG+L,QAAQ,KAG9D,sBAAanC,MAAO9L,EAAOgB,kBAA3B,UACE,8BAAM8M,IACN,wBACE5B,IAAK,SAACgC,GAAD,OAASxJ,EAAmB0D,QAAQlG,GAAKgM,GAC9ChO,OAAQwH,GACRvH,MAAOuH,GACPoE,MAAO,CACL5L,OAAQwH,GACRvH,MAAOuH,MAGX,8BAAMqG,IACN,8BAAMC,MAZE9L,MAmHTnB,SC/iBMoN,EAZS,SAAAC,GAClBA,GAAeA,aAAuBC,UACxC,8BAAqBzK,MAAK,YAAkD,IAA/C0K,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOF,GACPG,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAQN,OCDdO,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFpG,SAASC,eAAe,SAM1ByF,M","file":"static/js/main.658033c2.chunk.js","sourcesContent":["export const styles = {\n  root: {\n    height: \"100vh\",\n    width: \"100vw\",\n    display: \"flex\",\n    alignItems: \"stretch\",\n    backgroundColor: \"#E6EE9C\",\n    flexDirection: \"column\",\n  },\n  webCamParentPanel: {\n    width: \"100%\",\n    backgroundColor: \"#C5CAE9\",\n    display: \"flex\",\n    justifyContent: \"center\",\n    alignItems: \"center\",\n    flexDirection: \"row\",\n    margin: 0,\n    padding: 0,\n    gap: 0,\n  },\n  webCamPanel: {\n    display: \"flex\",\n    height: \"100%\",\n    backgroundColor: \"#FFF59D\",\n    justifyContent: \"center\",\n    alignItems: \"center\",\n    margin: 0,\n    padding: 0,\n    gap: 0,\n  },\n  settingPanel: {\n    display: \"flex\",\n    height: \"100%\",\n    backgroundColor: \"#FFF59D\",\n    justifyContent: \"center\",\n    alignItems: \"center\",\n    margin: 0,\n    padding: 0,\n    gap: 0,\n  },\n  faceMaskPanel: {\n    display: \"flex\",\n    backgroundColor: \"#BBDEFB\",\n    justifyContent: \"space-evenly\",\n    alignItems: \"center\",\n    margin: 0,\n    padding: 0,\n    gap: 0,\n  },\n  faceMaskContainer: {\n    display: \"flex\",\n    justifyContent: \"center\",\n    alignItems: \"center\",\n    margin: 0,\n    padding: 0,\n    gap: 0,\n    flexDirection: \"column\",\n  },\n  webCamStackItem: {\n    position: \"absolute\",\n    top: 0,\n    left: 0,\n    marginLeft: \"auto\",\n  },\n};\n","import { useState, useEffect } from \"react\";\n\nfunction getWindowDimensions() {\n  //   const { innerWidth: width, innerHeight: height } = window;\n  const { width, height } = window.visualViewport;\n  return {\n    width,\n    height,\n  };\n}\n\nexport const calcExpectedWebCamDim = (\n  windowHeight,\n  windowWidth,\n  verticalPanelSplitPercentage,\n  horizontalPanelSplitPercentage,\n  webCamRatios\n) => {\n  const webCamPanelHeight = (windowHeight * verticalPanelSplitPercentage) / 100;\n  const webCamPanelWidth = (windowWidth * horizontalPanelSplitPercentage) / 100;\n  const targetWebCamHeight = webCamPanelWidth / webCamRatios[0];\n  const targetWebCamWidth = webCamPanelHeight * webCamRatios[0];\n  let expectedWebCamHeight = webCamPanelHeight;\n  let expectedWebCamWidth = webCamPanelWidth;\n  if (targetWebCamHeight > webCamPanelHeight) {\n    expectedWebCamWidth = targetWebCamWidth;\n  } else {\n    expectedWebCamHeight = targetWebCamHeight;\n  }\n\n  return {\n    webCamPanelWidth: webCamPanelWidth,\n    webCamPanelHeight: webCamPanelHeight,\n    expectedWebCamWidth: expectedWebCamWidth,\n    expectedWebCamHeight: expectedWebCamHeight,\n  };\n};\n\nexport const calcExpectedImgDim = (\n  oriImgWidth,\n  oriImgHeight,\n  webCamPanelWidth,\n  webCamPanelHeight\n) => {\n  const oriImgRatio = oriImgWidth / oriImgHeight;\n  const targetImgHeight = webCamPanelWidth / oriImgRatio;\n  const targetImgWidth = webCamPanelHeight * oriImgRatio;\n  let expectedImgHeight = webCamPanelHeight;\n  let expectedImgWidth = webCamPanelWidth;\n  if (targetImgHeight > webCamPanelHeight) {\n    expectedImgWidth = targetImgWidth;\n  } else {\n    expectedImgHeight = targetImgHeight;\n  }\n  return {\n    expectedImgWidth: expectedImgWidth,\n    expectedImgHeight: expectedImgHeight,\n  };\n};\n\nexport const buildDetectedObjects = (\n  scores,\n  threshold,\n  boxes,\n  drawHeight,\n  drawWidth,\n  captureHeight,\n  captureWidth\n) => {\n  const detectionObjects = [];\n\n  let i = 0;\n  const len = scores.length;\n  while (i < len) {\n    if (scores[i] < threshold) {\n      break;\n    }\n    const bbox = [];\n    const minY = boxes[0][i][0] * drawHeight;\n    const minX = boxes[0][i][1] * drawWidth;\n    const maxY = boxes[0][i][2] * drawHeight;\n    const maxX = boxes[0][i][3] * drawWidth;\n    bbox[0] = minX;\n    bbox[1] = minY;\n    bbox[2] = maxX - minX;\n    bbox[3] = maxY - minY;\n    // index for sliding\n    const oriMinY = parseInt(boxes[0][i][0] * captureHeight);\n    const oriMinX = parseInt(boxes[0][i][1] * captureWidth);\n    const oriMaxY = parseInt(boxes[0][i][2] * captureHeight);\n    const oriMaxX = parseInt(boxes[0][i][3] * captureWidth);\n    const slideBox = [\n      oriMinY,\n      oriMinX,\n      oriMaxY - oriMinY + 1,\n      oriMaxX - oriMinX + 1,\n    ];\n    detectionObjects.push({\n      label: \"face\",\n      score: scores[i],\n      bbox: bbox,\n      slideBox: slideBox,\n      cropBox: boxes[0][i],\n      boxInd: i,\n    });\n    i++;\n  }\n  return detectionObjects;\n};\n\nconst readImageFile = (file) => {\n  return new Promise((resolve) => {\n    const reader = new FileReader();\n\n    reader.onload = () => resolve(reader.result);\n\n    reader.readAsDataURL(file);\n  });\n};\n\nconst createHTMLImageElement = (imageSrc) => {\n  return new Promise((resolve) => {\n    const img = new Image();\n\n    img.onload = () => resolve(img);\n\n    img.src = imageSrc;\n  });\n};\n\nexport const getWebCamInfos = async () => {\n  if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {\n    console.log(\"enumerateDevices() not supported.\");\n    return [\n      {\n        deviceName: null,\n        deviceId: null,\n      },\n    ];\n  }\n  return await navigator.mediaDevices\n    .enumerateDevices()\n    .then(function (devices) {\n      let webCamInfos = [];\n      let i = 0;\n      const len = devices.length;\n      while (i < len) {\n        if (devices[i].kind === \"videoinput\") {\n          webCamInfos.push({\n            deviceName: devices[i].label,\n            deviceId: devices[i].deviceId,\n          });\n        }\n        i++;\n      }\n      return webCamInfos;\n    })\n    .catch(function (err) {\n      console.log(err.name + \": \" + err.message);\n      return [\n        {\n          deviceName: null,\n          deviceId: null,\n        },\n      ];\n    });\n};\n\n/**\n * Hooks for getting dimension of the browser window\n */\nexport function useWindowDimensions() {\n  const [windowDimensions, setWindowDimensions] = useState(\n    getWindowDimensions()\n  );\n\n  useEffect(() => {\n    function handleResize() {\n      setWindowDimensions(getWindowDimensions());\n    }\n\n    window.addEventListener(\"resize\", handleResize);\n    return () => window.removeEventListener(\"resize\", handleResize);\n  }, []);\n\n  return windowDimensions;\n}\n\n// const onCapture = async (detectionModel, classificationModel) => {\n//   if (\n//     !isUsingWebcam ||\n//     detectionModel == null ||\n//     classificationModel == null\n//   ) {\n//     return;\n//   }\n//   if (\n//     typeof webcamRef.current !== \"undefined\" &&\n//     webcamRef.current !== null &&\n//     webcamRef.current.video.readyState === 4\n//   ) {\n//     // tf.engine().startScope();\n//     /** @type {HTMLVideoElement} */\n//     const video = webcamRef.current.video;\n\n//     // Set video width\n//     webcamRef.current.video.width = expectedWebCamWidth;\n//     webcamRef.current.video.height = expectedWebCamHeight;\n\n//     const cnvs = document.getElementById(\"myCanvas\");\n//     cnvs.width = expectedWebCamWidth;\n//     cnvs.height = expectedWebCamHeight;\n\n//     const ctx = cnvs.getContext(\"2d\");\n\n//     // Font options.\n//     const font = \"16px sans-serif\";\n//     ctx.font = font;\n//     ctx.textBaseline = \"top\";\n\n//     /** @type {tf.Tensor3D} */\n//     const rawImgTensor = tf.browser.fromPixels(video);\n//     const inputTensor = tf.tidy(() => {\n//       return rawImgTensor.transpose([0, 1, 2]).expandDims();\n//     });\n//     // let startTime = performance.now();\n//     detectionModel\n//       .executeAsync(inputTensor)\n//       .then((res) => {\n//         // const a0 = res[0].arraySync(); // num_detection\n//         // const a1 = res[1].arraySync(); // raw_detection_boxes\n//         // const a2 = res[2].arraySync(); // detection_anchor_indices\n//         // const a3 = res[3].arraySync(); // raw_detection_scores\n//         // const a4 = res[4].arraySync(); // detection_boxes\n//         // const a5 = res[5].arraySync(); // detection_classes\n//         // const a6 = res[6].arraySync(); // detection_scores\n//         // const a7 = res[7].arraySync(); // detection_multiclass_scores\n//         const detection_boxes = res[4].arraySync();\n//         const detection_classes = res[5].arraySync();\n//         const detection_scores = res[6].dataSync();\n\n//         const detections = utils.buildDetectedObjects(\n//           detection_scores,\n//           0.5,\n//           detection_boxes,\n//           detection_classes,\n//           expectedWebCamHeight,\n//           expectedWebCamWidth,\n//           720,\n//           1280\n//         );\n\n//         // prepare variables\n//         let i;\n//         let len;\n//         let limitLen;\n//         const _faceDetectionScores = Array(maxNumOfDisplayFace).fill(null);\n//         const _maskClassificationScores =\n//           Array(maxNumOfDisplayFace).fill(null);\n\n//         if (detections.length > 0) {\n//           // loop for rendering bounding boxes\n//           i = 0;\n//           len = detections.length;\n//           limitLen = maxNumOfDisplayFace;\n\n//           // clear bounding box canvas\n//           ctx.clearRect(0, 0, expectedWebCamHeight, expectedWebCamWidth);\n//           while (i < len) {\n//             const x = detections[i][\"bbox\"][0];\n//             const y = detections[i][\"bbox\"][1];\n//             const width = detections[i][\"bbox\"][2];\n//             const height = detections[i][\"bbox\"][3];\n\n//             // Draw the bounding box.\n//             ctx.strokeStyle = \"#00FFFF\";\n//             ctx.lineWidth = 4;\n//             ctx.strokeRect(x, y, width, height);\n\n//             // Draw the label background.\n//             ctx.fillStyle = \"#00FFFF\";\n//             const textWidth = ctx.measureText(\n//               detections[i][\"label\"] +\n//                 \" \" +\n//                 (100 * detections[i][\"score\"]).toFixed(2) +\n//                 \"%\"\n//             ).width;\n//             const textHeight = parseInt(font, 10); // base 10\n//             ctx.fillRect(x, y, textWidth + 4, textHeight + 4);\n\n//             if (i < limitLen) {\n//               // store confidence score\n//               _faceDetectionScores[i] = detections[i].score;\n//             }\n//             i++;\n//           }\n\n//           detections.forEach((item) => {\n//             const x = item[\"bbox\"][0];\n//             const y = item[\"bbox\"][1];\n\n//             // Draw the text last to ensure it's on top.\n//             ctx.fillStyle = \"#000000\";\n//             ctx.fillText(\n//               item[\"label\"] + \" \" + (100 * item[\"score\"]).toFixed(2) + \"%\",\n//               x,\n//               y\n//             );\n//           });\n\n//           // crop resize\n//           const boxes = detections.map((value, index) => value.cropBox);\n//           const boxInd = detections.map((value, index) => value.boxInd);\n//           const stackImgTensor = tf.tidy(() => {\n//             return rawImgTensor\n//               .tile([boxInd.length, 1, 1])\n//               .reshape([-1, rawImgTensor.shape[0], rawImgTensor.shape[1], 3]);\n//           });\n\n//           const resizeImgsTensor = tf.tidy(() => {\n//             return tf.image.cropAndResize(\n//               stackImgTensor,\n//               boxes,\n//               boxInd,\n//               [224, 224],\n//               \"bilinear\"\n//             );\n//           });\n//           const _maskConfidenceScoresTensor =\n//             classificationModel.execute(resizeImgsTensor);\n//           const _allMaskClassificationScores =\n//             _maskConfidenceScoresTensor.arraySync();\n\n//           i = 0;\n//           len = multiFaceCanvasRef.current.length;\n//           limitLen = detections.length;\n//           const returnedImgs = resizeImgsTensor.arraySync();\n//           while (i < len) {\n//             if (i < limitLen) {\n//               let faceCanvas = multiFaceCanvasRef.current[i];\n//               tf.browser.toPixels(returnedImgs[i], faceCanvas);\n\n//               _maskClassificationScores[i] =\n//                 _allMaskClassificationScores[i][0];\n//             } else {\n//               const context = multiFaceCanvasRef.current[i].getContext(\"2d\");\n//               context.clearRect(\n//                 0,\n//                 0,\n//                 multiFaceCanvasRef.current[i].width,\n//                 multiFaceCanvasRef.current[i].height\n//               );\n//             }\n//             i++;\n//           }\n//           // dispose all tensor variables\n//           stackImgTensor.dispose();\n//           resizeImgsTensor.dispose();\n//           _maskConfidenceScoresTensor.dispose();\n//         } else {\n//           // clear bounding box canvas\n//           ctx.clearRect(0, 0, expectedWebCamHeight, expectedWebCamWidth);\n\n//           // clear face render canvas\n//           i = 0;\n//           len = multiFaceCanvasRef.current.length;\n//           while (i < len) {\n//             const context = multiFaceCanvasRef.current[i].getContext(\"2d\");\n//             context.clearRect(\n//               0,\n//               0,\n//               multiFaceCanvasRef.current[i].width,\n//               multiFaceCanvasRef.current[i].height\n//             );\n//             i++;\n//           }\n//         }\n\n//         setFaceDetectionScores(_faceDetectionScores);\n//         setMaskClassificationScores(_maskClassificationScores);\n//         // let endTime = performance.now();\n//         // console.log(`Took ${endTime - startTime} milliseconds`);\n//         return res;\n//       })\n//       .then((res) => {\n//         let i = 0;\n//         const len = res.length;\n//         while (i < len) {\n//           tf.dispose(res[i]);\n//           i++;\n//         }\n//       })\n//       .finally(() => {\n//         tf.dispose(rawImgTensor);\n//         tf.dispose(inputTensor);\n//       });\n//     console.log(`numTensors: ${tf.memory().numTensors}`);\n//     // tf.engine().endScope();\n//   }\n// };\n","import FormControl from \"@mui/material/FormControl\";\nimport FormControlLabel from \"@mui/material/FormControlLabel\";\nimport FormGroup from \"@mui/material/FormGroup\";\nimport InputLabel from \"@mui/material/InputLabel\";\nimport MenuItem from \"@mui/material/MenuItem\";\nimport Select from \"@mui/material/Select\";\nimport Switch from \"@mui/material/Switch\";\nimport * as tf from \"@tensorflow/tfjs\";\nimport React, { useEffect, useRef, useState } from \"react\";\nimport Webcam from \"react-webcam\";\nimport \"./App.css\";\nimport { styles } from \"./styles\";\nimport * as utils from \"./utils\";\n\nconst webCamRatios = [16 / 9, 4 / 3];\nconst verticalPanelSplitPercentage = 65;\nconst horizontalPanelSplitPercentage = 70;\nconst maxNumOfDisplayFace = 5;\n\nconst face_detection_model_url = \"tfjs/face_detection/model.json\";\nconst face_mask_classification_model_url =\n  \"tfjs/face_mask_classification/model.json\";\nconst test_img_url = `${process.env.PUBLIC_URL}/test_imgs/mask_01.jpg`;\n\nfunction App() {\n  const webcamRef = useRef(null);\n  const multiFaceCanvasRef = useRef(Array(maxNumOfDisplayFace).fill(0));\n  const [faceDetectorProgress, setFaceDetectorProgress] = useState(0);\n  const [maskClassifierProgress, setMaskClassifierProgress] = useState(0);\n  const [faceDetectionScores, setFaceDetectionScores] = useState([]);\n  const [maskClassificationScores, setMaskClassificationScores] = useState([]);\n  const [detectionModel, setDetectionModel] = useState(null);\n  const [classificationModel, setClassificationModel] = useState(null);\n  const [testImgDim, setTestImgDim] = useState({});\n  const [isUsingWebcam, setIsUsingWebcam] = useState(false);\n  const [selectedWebCamInfo, setSelectedWebCamInfo] = useState({\n    deviceName: \"\",\n    deviceId: \"\",\n  });\n  const [availableWebCamInfos, setAvailableWebCamInfos] = useState([]);\n  const { height: windowHeight, width: windowWidth } =\n    utils.useWindowDimensions();\n\n  const {\n    webCamPanelWidth,\n    webCamPanelHeight,\n    expectedWebCamWidth,\n    expectedWebCamHeight,\n  } = utils.calcExpectedWebCamDim(\n    windowHeight,\n    windowWidth,\n    verticalPanelSplitPercentage,\n    horizontalPanelSplitPercentage,\n    webCamRatios\n  );\n  const oriImgWidth =\n    testImgDim.oriImgWidth !== undefined ? testImgDim.oriImgWidth : 0;\n  const oriImgHeight =\n    testImgDim.oriImgHeight !== undefined ? testImgDim.oriImgHeight : 1;\n  const { expectedImgWidth, expectedImgHeight } = utils.calcExpectedImgDim(\n    oriImgWidth,\n    oriImgHeight,\n    webCamPanelWidth,\n    webCamPanelHeight\n  );\n  const faceRenderCanvasHeight =\n    ((windowHeight * (100 - verticalPanelSplitPercentage)) / 100) * 0.5;\n\n  /**\n   * generate dynamic videoConstraintsValue\n   */\n  const videoConstraints = {\n    height: 720,\n    width: 1280,\n    // facingMode: \"environment\",\n    deviceId: selectedWebCamInfo.deviceId,\n  };\n\n  const loadModels = async () => {\n    /** @type {tf.GraphModel} */\n    if (detectionModel !== null) {\n      detectionModel.dispose();\n    }\n    if (classificationModel !== null) {\n      classificationModel.dispose();\n    }\n    const loadedDetectionModel = await tf.loadGraphModel(\n      face_detection_model_url,\n      {\n        onProgress: (fractions) => {\n          setFaceDetectorProgress(fractions);\n          // console.log(fractions);\n        },\n      }\n    );\n    const loadedClassificationModel = await tf.loadGraphModel(\n      face_mask_classification_model_url,\n      {\n        onProgress: (fractions) => {\n          setMaskClassifierProgress(fractions);\n          // console.log(fractions);\n        },\n      }\n    );\n    setDetectionModel(loadedDetectionModel);\n    setClassificationModel(loadedClassificationModel);\n    console.log(\"Model loaded.\");\n    return [loadedDetectionModel, loadedClassificationModel];\n  };\n\n  const onInferencing = async (detectionModel, classificationModel) => {\n    if (detectionModel == null || classificationModel == null) {\n      return;\n    }\n    let cnvs;\n    let inputData;\n    let drawHeight;\n    let drawWidth;\n    let captureHeight;\n    let captureWidth;\n\n    // either using webcam or test image\n    if (\n      typeof webcamRef.current !== \"undefined\" &&\n      webcamRef.current !== null &&\n      webcamRef.current.video.readyState === 4\n    ) {\n      /** @type {HTMLVideoElement} */\n      inputData = webcamRef.current.video;\n      cnvs = document.getElementById(\"myCanvas\");\n\n      // Set video width\n      webcamRef.current.video.width = expectedWebCamWidth;\n      webcamRef.current.video.height = expectedWebCamHeight;\n\n      cnvs.width = expectedWebCamWidth;\n      cnvs.height = expectedWebCamHeight;\n\n      // dimension variables\n      drawHeight = expectedWebCamHeight;\n      drawWidth = expectedWebCamWidth;\n      captureHeight = 720;\n      captureWidth = 1280;\n    } else if (!isUsingWebcam) {\n      /** @type {HTMLImageElement} */\n      inputData = document.getElementById(\"test_img\");\n      cnvs = document.getElementById(\"test_canvas\");\n\n      // force resize bounding box canvas\n      cnvs.width = expectedImgWidth;\n      cnvs.height = expectedImgHeight;\n\n      // dimension variables\n      drawHeight = expectedImgHeight;\n      drawWidth = expectedImgWidth;\n      captureHeight = expectedImgHeight;\n      captureWidth = expectedImgWidth;\n    } else {\n      return;\n    }\n\n    // tf.engine().startScope();\n    const ctx = cnvs.getContext(\"2d\");\n\n    // Font options.\n    const font = \"16px sans-serif\";\n    ctx.font = font;\n    ctx.textBaseline = \"top\";\n\n    /** @type {tf.Tensor3D} */\n    const rawImgTensor = tf.browser.fromPixels(inputData);\n    const inputTensor = tf.tidy(() => {\n      return rawImgTensor.transpose([0, 1, 2]).expandDims();\n    });\n    // let startTime = performance.now();\n    detectionModel\n      .executeAsync(inputTensor)\n      .then((res) => {\n        // const a0 = res[0].arraySync(); // num_detection\n        // const a1 = res[1].arraySync(); // raw_detection_boxes\n        // const a2 = res[2].arraySync(); // detection_anchor_indices\n        // const a3 = res[3].arraySync(); // raw_detection_scores\n        // const a4 = res[4].arraySync(); // detection_boxes\n        // const a5 = res[5].arraySync(); // detection_classes\n        // const a6 = res[6].arraySync(); // detection_scores\n        // const a7 = res[7].arraySync(); // detection_multiclass_scores\n        const detection_boxes = res[4].arraySync();\n        const detection_scores = res[6].dataSync();\n\n        const detections = utils.buildDetectedObjects(\n          detection_scores,\n          0.5,\n          detection_boxes,\n          drawHeight,\n          drawWidth,\n          captureHeight,\n          captureWidth\n        );\n\n        // prepare variables\n        let i;\n        let len;\n        let limitLen;\n        const _faceDetectionScores = Array(maxNumOfDisplayFace).fill(null);\n        const _maskClassificationScores = Array(maxNumOfDisplayFace).fill(null);\n\n        if (detections.length > 0) {\n          // loop for rendering bounding boxes\n          i = 0;\n          len = detections.length;\n          limitLen = maxNumOfDisplayFace;\n\n          // clear bounding box canvas\n          ctx.clearRect(0, 0, expectedWebCamHeight, expectedWebCamWidth);\n          while (i < len) {\n            const x = detections[i][\"bbox\"][0];\n            const y = detections[i][\"bbox\"][1];\n            const width = detections[i][\"bbox\"][2];\n            const height = detections[i][\"bbox\"][3];\n\n            // Draw the bounding box.\n            ctx.strokeStyle = \"#00FFFF\";\n            ctx.lineWidth = 2;\n            ctx.strokeRect(x, y, width, height);\n\n            if (i < limitLen) {\n              // store confidence score\n              _faceDetectionScores[i] = detections[i].score;\n            }\n            i++;\n          }\n\n          // crop resize\n          const boxes = detections.map((value, index) => value.cropBox);\n          const boxInd = detections.map((value, index) => value.boxInd);\n\n          const resizeImgsTensor = tf.tidy(() => {\n            const stackImgTensor = rawImgTensor\n              .tile([boxInd.length, 1, 1])\n              .reshape([-1, rawImgTensor.shape[0], rawImgTensor.shape[1], 3]);\n            return tf.image.cropAndResize(\n              stackImgTensor,\n              boxes,\n              boxInd,\n              [224, 224],\n              \"bilinear\"\n            );\n          });\n\n          const _allMaskClassificationScores = tf.tidy(() => {\n            return classificationModel.execute(resizeImgsTensor).arraySync();\n          });\n\n          // render faces\n          i = 0;\n          len = multiFaceCanvasRef.current.length;\n          limitLen = detections.length;\n          const returnedImgs = resizeImgsTensor.arraySync();\n          while (i < len) {\n            if (i < limitLen) {\n              let faceCanvas = multiFaceCanvasRef.current[i];\n              tf.browser.toPixels(returnedImgs[i], faceCanvas);\n\n              _maskClassificationScores[i] = _allMaskClassificationScores[i][0];\n            } else {\n              const context = multiFaceCanvasRef.current[i].getContext(\"2d\");\n              context.clearRect(\n                0,\n                0,\n                multiFaceCanvasRef.current[i].width,\n                multiFaceCanvasRef.current[i].height\n              );\n            }\n            i++;\n          }\n          // dispose all tensor variables\n          resizeImgsTensor.dispose();\n        } else {\n          // clear bounding box canvas\n          ctx.clearRect(0, 0, expectedWebCamHeight, expectedWebCamWidth);\n\n          // clear face render canvas\n          i = 0;\n          len = multiFaceCanvasRef.current.length;\n          while (i < len) {\n            const context = multiFaceCanvasRef.current[i].getContext(\"2d\");\n            context.clearRect(\n              0,\n              0,\n              multiFaceCanvasRef.current[i].width,\n              multiFaceCanvasRef.current[i].height\n            );\n            i++;\n          }\n        }\n\n        setFaceDetectionScores(_faceDetectionScores);\n        setMaskClassificationScores(_maskClassificationScores);\n        // let endTime = performance.now();\n        // console.log(`Took ${endTime - startTime} milliseconds`);\n        return res;\n      })\n      .then((res) => {\n        let i = 0;\n        const len = res.length;\n        while (i < len) {\n          tf.dispose(res[i]);\n          i++;\n        }\n      })\n      .finally(() => {\n        tf.dispose(rawImgTensor);\n        tf.dispose(inputTensor);\n      });\n    // console.log(`numTensors: ${tf.memory().numTensors}`);\n    // tf.engine().endScope();\n  };\n\n  /* \n    Run only once\n     */\n  useEffect(() => {\n    tf.ready()\n      .then((_) => {\n        tf.enableProdMode();\n        console.log(\"tfjs is ready\");\n      })\n      .then(loadModels);\n  }, []);\n\n  useEffect(() => {\n    if (detectionModel !== null && classificationModel !== null) {\n      if (isUsingWebcam) {\n        const captureInterval = setInterval(\n          onInferencing,\n          100,\n          detectionModel,\n          classificationModel\n        );\n        return () => clearInterval(captureInterval);\n      } else {\n        console.log(\"Run on test img\");\n        onInferencing(detectionModel, classificationModel);\n      }\n    }\n  }, [\n    classificationModel,\n    detectionModel,\n    windowHeight,\n    windowWidth,\n    isUsingWebcam,\n    testImgDim,\n  ]);\n\n  useEffect(() => {\n    if (!isUsingWebcam) {\n      const img = new Image();\n      img.src = test_img_url;\n      img.onload = () => {\n        setTestImgDim({\n          oriImgHeight: img.naturalHeight,\n          oriImgWidth: img.naturalWidth,\n        });\n      };\n    }\n  }, [isUsingWebcam]);\n\n  useEffect(() => {\n    setFaceDetectionScores(Array(maxNumOfDisplayFace).fill(null));\n    setMaskClassificationScores(Array(maxNumOfDisplayFace).fill(null));\n  }, [maxNumOfDisplayFace]);\n\n  useEffect(() => {\n    utils.getWebCamInfos().then((webCamInfos) => {\n      setAvailableWebCamInfos(webCamInfos);\n      if (webCamInfos.length > 0) {\n        setSelectedWebCamInfo(webCamInfos[0]);\n      }\n    });\n  }, [isUsingWebcam]);\n\n  const webCamToggle = () => {\n    return (\n      <Switch\n        checked={isUsingWebcam}\n        onChange={(event) => {\n          setIsUsingWebcam(event.target.checked);\n        }}\n        inputProps={{ \"aria-label\": \"controlled\" }}\n      />\n    );\n  };\n\n  const videoInputSelector = () => {\n    return (\n      <Select\n        labelId=\"demo-simple-select-autowidth-label\"\n        id=\"demo-simple-select-autowidth\"\n        value={selectedWebCamInfo.deviceId}\n        onChange={(event) => {\n          setSelectedWebCamInfo({\n            deviceName: event.target.name,\n            deviceId: event.target.value,\n          });\n        }}\n        autoWidth\n        label=\"Video Input\"\n      >\n        {availableWebCamInfos.length > 0 ? (\n          availableWebCamInfos.map((value, index) => {\n            return (\n              <MenuItem key={index} value={value.deviceId}>\n                {value.deviceName}\n              </MenuItem>\n            );\n          })\n        ) : (\n          <MenuItem value=\"\">{\"\"}</MenuItem>\n        )}\n      </Select>\n    );\n  };\n\n  const faceMaskPanel = () => {\n    if (detectionModel == null || classificationModel == null) {\n      const faceDetectionModelProgress = `Face Detection Model - ${\n        faceDetectorProgress * 100\n      }%`;\n      const maskClassifierModelProgress = `Mask Classifier Model - ${\n        maskClassifierProgress * 100\n      }%`;\n      return (\n        <div>\n          <div>{\"Downloading models....\"}</div>\n          <div>{faceDetectionModelProgress}</div>\n          <div>{maskClassifierModelProgress}</div>\n        </div>\n      );\n    } else if (multiFaceCanvasRef.current.length < 1) {\n      return <div>{\"Warming up....\"}</div>;\n    }\n    return multiFaceCanvasRef.current.map((item, i) => {\n      let labelName = \"\";\n      let faceScoreLabel = \"\";\n      let maskScoreLabel = \"\";\n      if (\n        faceDetectionScores[i] !== null &&\n        faceDetectionScores[i] !== undefined &&\n        maskClassificationScores[i] !== null &&\n        maskClassificationScores[i] !== undefined\n      ) {\n        labelName = maskClassificationScores[i] > 0 ? \"No Mask\" : \"Mask\";\n        faceScoreLabel = `Face: ${faceDetectionScores[i].toFixed(2)}`;\n        maskScoreLabel = `Mask: ${maskClassificationScores[i].toFixed(2)}`;\n      }\n      return (\n        <div key={i} style={styles.faceMaskContainer}>\n          <div>{labelName}</div>\n          <canvas\n            ref={(el) => (multiFaceCanvasRef.current[i] = el)}\n            height={faceRenderCanvasHeight}\n            width={faceRenderCanvasHeight}\n            style={{\n              height: faceRenderCanvasHeight,\n              width: faceRenderCanvasHeight,\n            }}\n          />\n          <div>{faceScoreLabel}</div>\n          <div>{maskScoreLabel}</div>\n        </div>\n      );\n    });\n  };\n\n  return (\n    <div className=\"App\" style={styles.root}>\n      <div\n        style={{\n          ...styles.webCamParentPanel,\n          flexBasis: `${verticalPanelSplitPercentage}%`,\n        }}\n      >\n        <div\n          style={{\n            ...styles.webCamPanel,\n            flexBasis: `${horizontalPanelSplitPercentage}%`,\n          }}\n        >\n          {isUsingWebcam && (\n            <div style={{}}>\n              <Webcam\n                audio={false}\n                style={{\n                  ...styles.webCamStackItem,\n                  height: expectedWebCamHeight,\n                  width: expectedWebCamWidth,\n                }}\n                id=\"img\"\n                ref={webcamRef}\n                height={expectedWebCamHeight}\n                width={expectedWebCamWidth}\n                screenshotQuality={1}\n                screenshotFormat=\"image/jpeg\"\n                videoConstraints={videoConstraints}\n              />\n              <canvas\n                id=\"myCanvas\"\n                height={expectedWebCamHeight}\n                width={expectedWebCamWidth}\n                style={{\n                  ...styles.webCamStackItem,\n                  zIndex: 9999,\n                  backgroundColor: \"transparent\",\n                }}\n              />\n            </div>\n          )}\n          {!isUsingWebcam && (\n            <div style={{}}>\n              <img\n                id=\"test_img\"\n                src={test_img_url}\n                style={{\n                  ...styles.webCamStackItem,\n                  height: expectedImgHeight,\n                  width: expectedImgWidth,\n                }}\n                height={expectedImgHeight}\n                width={expectedImgWidth}\n                alt=\"\"\n              />\n              <canvas\n                id=\"test_canvas\"\n                height={expectedImgHeight}\n                width={expectedImgWidth}\n                style={{\n                  ...styles.webCamStackItem,\n                  zIndex: 9999,\n                  backgroundColor: \"transparent\",\n                }}\n              />\n            </div>\n          )}\n        </div>\n        <div\n          style={{\n            ...styles.settingPanel,\n            flexBasis: `${100 - horizontalPanelSplitPercentage}%`,\n          }}\n        >\n          <FormGroup>\n            <FormControl sx={{ m: 1, minWidth: 220 }} size=\"small\">\n              <InputLabel id=\"demo-simple-select-autowidth-label\">\n                Video Input\n              </InputLabel>\n              {videoInputSelector()}\n            </FormControl>\n            <FormControlLabel\n              control={webCamToggle()}\n              label=\"Webcam\"\n              labelPlacement=\"start\"\n            />\n          </FormGroup>\n        </div>\n      </div>\n      <div\n        style={{\n          ...styles.faceMaskPanel,\n          flexBasis: `${100 - verticalPanelSplitPercentage}%`,\n        }}\n      >\n        {faceMaskPanel()}\n      </div>\n    </div>\n  );\n}\n\nexport default App;\n","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}